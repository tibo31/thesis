---
title: "Supplementary Material – Climate Change Assessment Across Countries: Statistical Construction and Exploration of Annual Indicators"
author: "Thibault Laurent, Abdelaati Daouia, Paula Margaretic, Zaineb Smida, Christine Thomas-Agnan"
date: "Last Update: `r format(Sys.Date(), '%d %B %Y')`"
header-includes:
- \usepackage{booktabs}
- \usepackage{makecell}
- \usepackage[mathscr]{eucal}
output :
  rmdformats::html_clean:
    toc: true
    number_sections: yes
    fig_caption: true
    template: flatly
    code_folding: hide 
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Required packages :
```{r, eval = F}
install.packages(c(
  "fda",
  "ncdf4",
  "dichromat",
  "sf",
  "mapsf",
  "maptiles",
  "geodata",
  "tidyverse",
  "terra"))
```


```{r, message = F}
library(ncdf4)
library(dichromat)
library(fda)
library(sf)
library(mapsf)
library(maptiles)
library(progress)
library(tidyverse)
library(terra)
library(latex2exp)
library(maptiles)
```

This supplementary document provides the technical materials associated with the chapter Climate Change Assessment Across Countries: A Statistical Approach to the Construction and Exploration of Annual Indicators. It includes the full set of R scripts and selected outputs used to generate the national-level climate indicators discussed in the main text. The indicators are derived from MERRA-2 daily gridded data and are computed for the period 1981–2024 across 262 countries and territories.
The code is organized to reproduce the construction pipeline described in the article/thesis: from the extraction of grid-level data, to temporal aggregation, population-weighted spatial interpolation, and the generation of distribution-sensitive indicators (including quantile-, extremile-, and expected shortfall-based measures). In addition, this document includes extended exploratory tools, robustness checks, and figures not shown in the printed version but relevant for replication or further use.

All materials are intended to facilitate transparency, reproducibility, and potential extensions of the proposed methodology.



# Data sources and geographic framework

## MERRA-2 climate variables

### Data Download Process 

The MERRA-2 data can be accessed via NASA's website: https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/data_access/. To download the data, users must first create a NASA Earthdata account. The full catalog contains a wide range of climate variables with varying temporal resolutions, accessible at: https://disc.gsfc.nasa.gov/datasets?project=MERRA-2.

In this study, we use two specific datasets:

* **M2SDNXSLV** (`statD_2d_slv_Nx`): A two-dimensional daily dataset that provides daily summary statistics such as mean air temperature at 2 meters (`T2MEAN`), as well as daily minimum (`T2MIN`) and maximum (`T2MAX`) temperatures.

* **M2T1NXFLX** (`tavg1_2d_flx_Nx`): A two-dimensional dataset of hourly time-averaged surface flux diagnostics, including variables like total precipitation and bias-corrected total precipitation (`PRECTOTCORR`).

While the website allows users to subset the data interactively via the Subset / Get Data tool, our analysis requires full global coverage (i.e., all $N = 207{,}936$ grid cells) over the full time span from January 1, 1981 to December 31, 2024, representing $16{,}071$ days.

Once the data request is submitted, NASA provides a text file (here referred to as `"subset_file_NASA.txt"`) containing download URLs-one per daily file. Consequently, for each variable set, we need to download $16{,}071$ `.nc4` files: one per day for temperature, and one per day for precipitation. These files are stored in the directories `"ncf_temp/"` and `"ncf_prec/"`, respectively.

Below are the first three lines of this file:
```{bash, eval = F}
https://goldsmr4.gesdisc.eosdis.nasa.gov/data/MERRA2/M2T1NXFLX.5.12.4/doc/MERRA2.README.pdf
https://data.gesdisc.earthdata.nasa.gov/data/MERRA2/M2T1NXFLX.5.12.4/1981/01/MERRA2_100.tavg1_2d_flx_Nx.19810101.nc4
https://data.gesdisc.earthdata.nasa.gov/data/MERRA2/M2T1NXFLX.5.12.4/1981/01/MERRA2_100.tavg1_2d_flx_Nx.19810102.nc4
https://data.gesdisc.earthdata.nasa.gov/data/MERRA2/M2T1NXFLX.5.12.4/1981/01/MERRA2_100.tavg1_2d_flx_Nx.19810103.nc4
https://data.gesdisc.earthdata.nasa.gov/data/MERRA2/M2T1NXFLX.5.12.4/1981/01/MERRA2_100.tavg1_2d_flx_Nx.19810104.nc4
```

To download the data, we have to open a Terminal and execute the following command:  
```{bash, eval = F}
wget --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --keep-session-cookies --content-disposition -i "subset_file_NASA.txt" --user my_user_name --password my_password
```

```{bash, eval = F, echo = F}
wget --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --keep-session-cookies --content-disposition -i "subset_M2SDNXSLV_5.12.4_20250219_183850_.txt" --user tibo_sur_son31 --password Aminou_3120935R
```

The total size of the temperature data—comprising three daily variables (`T2MEAN`, `T2MIN`, and `T2MAX`)-is approximately 27 GB, while the precipitation data (`PRECTOTCORR`, available hourly) amounts to roughly 195 GB.

**Note 1**: All files are organized into subdirectories by year, from 1981 to 2024.

**Note 2**: Due to memory limitations, it is not feasible to load the entire dataset simultaneously in `R`. In total, the dataset contains $N \times 16{,}071 \times 4$ values, where: $N = 207{,}936$ is the number of spatial cells, $16{,}071$ is the number of days in the study period, and 4 represents the number of climate variables (`T2MIN`, `T2MEAN`, `T2MAX`, and `PRECTOTCORR`).

Our goal is to compute $p = 14$ annual climate indicators for each year from 1981 to 2024 ($T = 44$ years), resulting in a matrix of size $N \times T \times p$ that remains manageable in memory.

To handle the data efficiently, we begin by generating one output file per observation cell, allowing for scalable processing and memory-friendly storage.

### Managing the Data in R 

Our objective is to generate $N$ CSV files, one for each spatial cell, where each file contains a table of size $16{,}071 \times 5$ with the following variables:

* `my_date`: the date of observation (from January 1, 1981 to December 31, 2024),
* `t2m`: the daily mean temperature,
* `t2min`: the daily minimum temperature,
* `t2max`: the daily maximum temperature,
* `prec`: the total corrected precipitation per day.

We begin by initializing the required vectors, including:

* the sequences of longitudes and latitudes corresponding to the MERRA-2 grid,
* the full date sequence covering the $16{,}071$ days of the study period.

```{r, eval = T}
long_seq <- seq(-180, 179.5, by = 0.625)
lat_seq <- seq(-90, 90, by = 0.5)
N <- length(long_seq) * length(lat_seq)
all_days <- seq.Date(from = as.Date("1981-01-01"), to = as.Date("2024-12-31"), by = 1)
nT <- length(all_days)
unique_nom_file <- data.frame(
  cell = 1:N,
  long = rep(long_seq, times = length(lat_seq)), 
  lat = rep(lat_seq, each = length(long_seq)))
```

We use the **ncf** package to import the climate data stored in the `.nc4` format. The files are processed day by day, and the extracted data are then saved cell by cell in `.csv` format. To handle the large data volume efficiently, the workflow is optimized for parallel computing. Using 4 CPU cores, the full extraction and saving process takes approximately 30 hours.


```{r, eval = F}
library("ncdf4")
# import temperature files
nom_vars <- c("T2MMAX", "T2MMEAN", "T2MMIN")
nom_annee <- as.character(1981:2023)
list_annee <- list(
  as.character(1981:1984),
  as.character(1985:1988),
  as.character(1989:1992),
  as.character(1993:1996),
  as.character(1997:2000),
  as.character(2001:2004),
  as.character(2005:2008),
  as.character(2009:2012),
  as.character(2013:2016),
  as.character(2017:2020),
  as.character(2021:2023)
)
  
my_time <- proc.time()

for(r in 1:length(list_annee)) {
  print(proc.time() - my_time)
  all_days_year <- seq.Date(from = as.Date(paste0(list_annee[[r]][1], "-01-01")), 
                      to = as.Date(paste0(list_annee[[r]][length(list_annee[[r]])], "-12-31")), 
                      by = 1)
  nT <- length(all_days_year)
  t2m <- t2min <- t2max <- data.frame(matrix(ncol = nT, nrow = N))
  prec <- data.frame(matrix(ncol = nT, nrow = N))
  names(t2m) <- names(t2min) <- names(t2max) <- names(prec) <- all_days_year
  
for(i in list_annee[[r]]) {
  print(i)
  print(proc.time() - my_time)
  my_file <- dir(paste0("MERRA2/", i))
  n_days_per_year <- length(my_file)

  for (k in 1:length(my_file)) {
    day_k <- paste0(
      substr(my_file[k], nchar(my_file[k])-11, nchar(my_file[k])-8), "-",
      substr(my_file[k], nchar(my_file[k])-7, nchar(my_file[k])-6), "-",
      substr(my_file[k], nchar(my_file[k])-5, nchar(my_file[k])-4))
    
    our_nc_data <- nc_open(paste0("MERRA2/", i, "/", my_file[k]))
    # Extract the variables from the NASA data
    for (j in nom_vars) {
      lswt_array <- ncvar_get(our_nc_data, j) 
      fillvalue <- ncatt_get(our_nc_data, j, "_FillValue")
      #right away let's replace the nc FillValues with NAs
      lswt_array[lswt_array == fillvalue$value] <- NA
      if (j == "T2MMEAN") {
        t2m[, day_k] <- as.vector(lswt_array - 273.1)
      } else {
          if (j == "T2MMIN") {
            t2min[, day_k] <- as.vector(lswt_array - 273.1)
          } else {
            t2max[, day_k] <- as.vector(lswt_array - 273.1)
          }
       }
    }
    nc_close(our_nc_data)
  }
  
  # import precipitation data 
  my_file <- dir(paste0("PRECTOTCORR/", i))
  # import
  for(k in 1:length(my_file)) {
    day_k <- paste0(
      substr(my_file[k], nchar(my_file[k])-15, nchar(my_file[k])-12), "-",
      substr(my_file[k], nchar(my_file[k])-11, nchar(my_file[k])-10), "-",
      substr(my_file[k], nchar(my_file[k])-9, nchar(my_file[k])-8))
    
    our_nc_data <- nc_open(paste0("PRECTOTCORR/", i, "/", my_file[k]))
    # Extract the variables from the NASA data
    lswt_array <- ncvar_get(our_nc_data, "PRECTOTCORR") 
    fillvalue <- ncatt_get(our_nc_data, "PRECTOTCORR", "_FillValue")
    #right away let's replace the nc FillValues with NAs
    lswt_array[lswt_array == fillvalue$value] <- NA
    prec[, day_k] <- as.vector(apply(lswt_array, c(1, 2), sum) * 3600)
    nc_close(our_nc_data)
  }
 
} 
  my_export <- function(vec_z) {
    for(z in 1:length(vec_z)) {
      temp <- data.frame(my_date = all_days_year,
                         t2m = as.numeric(t2m[vec_z[z], ]),
                         t2min = as.numeric(t2min[vec_z[z], ]),
                         t2max = as.numeric(t2max[vec_z[z], ]),
                         prectotcorr = as.numeric(prec[vec_z[z], ]))
      write.table(temp, 
                  row.names = FALSE, sep = ";", append = T, col.names = F,
                  file = paste0("cell/cell_", vec_z[z], ".csv")) 
    }
  }
  
  list_z <- list(
    (1:51984),
    (51985:103968),
    (103969:155952),
    (155953:207936)
  )
  require(parallel)
  cl <- makeCluster(4)
  clusterExport(cl, c("t2m", "t2min", "t2max", "prec", "all_days_year"))
  system.time(
    clusterApply(cl, list_z, fun = my_export)
    )
  stopCluster(cl)
}

# Task for adding a new year of observation (2024 for example) 
# import temperature files
nom_vars <- c("T2MMAX", "T2MMEAN", "T2MMIN")
nom_annee <- as.character(2024)
list_annee <- list(as.character(2024))
  
my_time <- proc.time()

for(r in 1:length(list_annee)) {
  print(proc.time() - my_time)
  all_days_year <- seq.Date(from = as.Date(paste0(list_annee[[r]][1], "-01-01")), 
                      to = as.Date(paste0(list_annee[[r]][length(list_annee[[r]])], "-12-31")), 
                      by = 1)
  nT <- length(all_days_year)
  t2m <- t2min <- t2max <- data.frame(matrix(ncol = nT, nrow = N))
  prec <- data.frame(matrix(ncol = nT, nrow = N))
  names(t2m) <- names(t2min) <- names(t2max) <- names(prec) <- all_days_year
  
for(i in list_annee[[r]]) {
  print(i)
  print(proc.time() - my_time)
  my_file <- dir(paste0("MERRA2/", i))
    for (k in 1:length(my_file)) {
      file.rename(paste0("MERRA2/", i, "/", my_file[k]), 
              paste0("MERRA2/", i, "/", substr(my_file[k], 1, 39)))
    }
  my_file <- dir(paste0("MERRA2/", i))
  n_days_per_year <- length(my_file)

  for (k in 1:length(my_file)) {
    day_k <- paste0(
      substr(my_file[k], nchar(my_file[k])-11, nchar(my_file[k])-8), "-",
      substr(my_file[k], nchar(my_file[k])-7, nchar(my_file[k])-6), "-",
      substr(my_file[k], nchar(my_file[k])-5, nchar(my_file[k])-4))
    
    our_nc_data <- nc_open(paste0("MERRA2/", i, "/", my_file[k]))
    # Extract the variables from the NASA data
    for (j in nom_vars) {
      lswt_array <- ncvar_get(our_nc_data, j) 
      fillvalue <- ncatt_get(our_nc_data, j, "_FillValue")
      #right away let's replace the nc FillValues with NAs
      lswt_array[lswt_array == fillvalue$value] <- NA
      if (j == "T2MMEAN") {
        t2m[, day_k] <- as.vector(lswt_array - 273.1)
      } else {
          if (j == "T2MMIN") {
            t2min[, day_k] <- as.vector(lswt_array - 273.1)
          } else {
            t2max[, day_k] <- as.vector(lswt_array - 273.1)
          }
       }
    }
    nc_close(our_nc_data)
  }
  
  # import precipitation data 
  my_file <- dir(paste0("PRECTOTCORR/", i))
  for (k in 1:length(my_file)) {
      file.rename(paste0("PRECTOTCORR/", i, "/", my_file[k]), 
              paste0("PRECTOTCORR/", i, "/", substr(my_file[k], 1, 39)))
    }
  
  my_file <- dir(paste0("PRECTOTCORR/", i))
  # import
  for(k in 1:length(my_file)) {
    print(k)
    day_k <- paste0(
      substr(my_file[k], nchar(my_file[k])-11, nchar(my_file[k])-8), "-",
      substr(my_file[k], nchar(my_file[k])-7, nchar(my_file[k])-6), "-",
      substr(my_file[k], nchar(my_file[k])-5, nchar(my_file[k])-4))
    
    our_nc_data <- nc_open(paste0("PRECTOTCORR/", i, "/", my_file[k]))
    # Extract the variables from the NASA data
    lswt_array <- ncvar_get(our_nc_data, "PRECTOTCORR") 
    fillvalue <- ncatt_get(our_nc_data, "PRECTOTCORR", "_FillValue")
    #right away let's replace the nc FillValues with NAs
    lswt_array[lswt_array == fillvalue$value] <- NA
    prec[, day_k] <- as.vector(apply(lswt_array, c(1, 2), sum) * 3600)
    nc_close(our_nc_data)
  }
 
} 
  my_export <- function(vec_z) {
    for(z in 1:length(vec_z)) {
      temp <- data.frame(my_date = all_days_year,
                         t2m = as.numeric(t2m[vec_z[z], ]),
                         t2min = as.numeric(t2min[vec_z[z], ]),
                         t2max = as.numeric(t2max[vec_z[z], ]),
                         prectotcorr = as.numeric(prec[vec_z[z], ]))
      write.table(temp, 
                  row.names = FALSE, sep = ";", append = T, col.names = F,
                  file = paste0("cell/cell_", vec_z[z], ".csv")) 
    }
  }
  
  list_z <- list(
    (1:51984),
    (51985:103968),
    (103969:155952),
    (155953:207936)
  )
  require(parallel)
  cl <- makeCluster(4)
  clusterExport(cl, c("t2m", "t2min", "t2max", "prec", "all_days_year"))
  system.time(
    clusterApply(cl, list_z, fun = my_export)
    )
  stopCluster(cl)
}
```


**Note**: Upon completion of this step, we obtain $N$ CSV files, each of size $16{,}071 \times 5$, totaling approximately 300 GB of data. While it remains impractical to load the entire dataset into memory at once, the data are now structured in a way that facilitates more efficient computation of long-term climate normals (e.g., average temperatures and precipitation).


### Illustration of the MERRA-2 Data

We provide the code used to generate the figure titled  *Exploratory analysis of daily temperature and precipitation at the Geneva grid cell ($s = \text{Geneva}$) for the year 2024. The panels display: (left) daily time series for maximum, mean, and minimum temperature (top row) and daily precipitation (bottom row); (middle) kernel density estimates; and (right) empirical cumulative distribution functions (ECDFs). These visualizations summarize both the temporal dynamics and the distributional properties of the variables.*

```{r, message = F}
my_proj <- '+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs'
coord_region <- st_as_sf(unique_nom_file, coords = c("long", "lat"),
                         crs = 4326)

# transforn the points into grid
long_lat_temp <- unique_nom_file[, c("long", "lat")] %>%
  filter(lat > -90, lat < 90, long > -180, long < 180) %>%
  arrange(lat, long)   %>%
  dplyr::select(long, lat)
df_sf_temp <- st_as_sf(long_lat_temp, coords = c("long", "lat"))
st_crs(df_sf_temp) <- 4326
all_cells <- df_sf_temp %>% 
  st_make_grid(cellsize = c(0.625, 0.5), 
               offset = c(-179.375 - 0.3125, -89.5 -0.25)) %>% # c(-180 - 0.3125, -90 - 0.25))
  st_as_sf() %>% 
  st_join(df_sf_temp) %>%
  st_transform(my_proj) # CRS used later on
all_cells$long <- long_lat_temp$long
all_cells$lat <- long_lat_temp$lat
```

```{r, fig.width = 10, fig.height = 6, warning = F}
deb_month <-  c(1, 32, 61, 92, 122, 153, 183, 214, 245, 275, 306, 336)
month.name <- paste0(month.abb, " 1 \n (d=", deb_month, ")")
cell_geneva <- read.table("data/cell_156971.csv",
    header = F, sep = ";", 
    colClasses = c("character", "numeric", "numeric", "numeric", "numeric"),
    col.names = c("YYYYMMDD", "T2MMEAN", "T2MMIN", "T2MMAX", "PRECTOTCORR")) %>%
  filter(substr(YYYYMMDD, 1, 4) >= "2024")
cell_geneva$YYYYMMDD <- as.Date(cell_geneva$YYYYMMDD)

#pdf("figures/merra_geneva.pdf", width = 10 * 0.8, height = 5 * 0.8)
par(oma = c(0, 0.3, 0, 0.2), mar = c(3.6, 3.7, 0.2, 0.1), 
    mgp = c(2.35, 0.65, 0), las = 1)
nf <- layout(matrix(c(1, 1, 2, 3, 4, 4, 5, 6), nrow=2, byrow=TRUE))

# map
geneva_cell <- all_cells[156123, ]
CH <- all_cells[sapply(st_intersects(all_cells, st_buffer(geneva_cell, 100000)), 
                       function(x) length(x) > 0 ), ]
          
CH_zoom <- st_intersection(all_cells, st_buffer(geneva_cell, 50000))
geneva <- st_as_sf(data.frame(long = 6.143158, lat = 46.2044),
            coords = c("long", "lat"), crs = 4326)

# Temperatures 
# Time series
plot(1:366, cell_geneva$T2MMEAN, type = "l", 
     xlab = "Day of the year", col = "grey", 
     ylab = TeX(r'($T^{type}$ (in degree C))'), 
     ylim = c(-10, 33), xaxt = "n")
axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.04 * (par()$usr[4] - par()$usr[3]),
     labels = month.name, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)    
lines(1:366, cell_geneva$T2MMIN, col = "blue", lty = 2)
lines(1:366, cell_geneva$T2MMAX, col = "red", lty = 2)
legend("topleft", legend = c(TeX(r'($T^{MAX}_{Geneva, d, 2024}$)'),
                             TeX(r'($T^{MEAN}_{Geneva, d, 2024}$)'),
                             TeX(r'($T^{MIN}_{Geneva, d, 2024}$)')),
       lty = c(2, 1, 2), col = c("red", "grey", "blue"), 
       bty = "n", cex = 0.9)

# density 
plot(density(cell_geneva$T2MMEAN), type = "l", 
         col = "grey", ylab = "Density", ylim = c(0, 0.055),
         xlab = TeX(r'($T^{type}$ (in degree C))'), main = "")
    
lines(density(cell_geneva$T2MMIN), col = "blue", lty = 2)
lines(density(cell_geneva$T2MMAX), col = "red", lty = 2)

# ecdf 
plot(ecdf(cell_geneva$T2MMEAN), pch = NA,
         col = "grey", ylab = "ECDF", ylim = c(0, 1),
         xlab = TeX(r'($T^{type}$ (in degree C))'), main = "")
    
lines(ecdf(cell_geneva$T2MMIN), pch = NA, col = "blue", lty = 2)
lines(ecdf(cell_geneva$T2MMAX), pch = NA, col = "red", lty = 2)

# Precipitation 
# Time series
plot(1:366, cell_geneva$PRECTOTCORR, type = "h", 
         col = "cyan", ylab = TeX(r'($P$ (in mm))'), 
         xlab = "Day of the year", ylim = c(0, 38), xaxt = "n")
axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.04 * (par()$usr[4] - par()$usr[3]),
     labels = month.name, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)    
# density 
plot(density(cell_geneva$PRECTOTCORR), type = "l", 
         col = "cyan", ylab = "Density", 
         xlab = TeX(r'($P$ (in mm))'), main = "")

# ecdf 
plot(ecdf(cell_geneva$PRECTOTCORR), pch = NA,
         col = "cyan", ylab = "ECDF", ylim = c(0, 1),
         xlab = TeX(r'($P$ (in mm))'), main = "")            
#dev.off()
```


## Spatial boundaries and population grids

### Spatial Boundaries

We import global country boundaries using the shapefile version curated by James (2024). To facilitate efficient processing and improve visualization performance, we apply geometric simplification to the country polygons while preserving their overall topology and spatial fidelity. These simplified contours are used throughout the analysis for spatial overlays and map production.

We present the map titled *Global map of the $n = 262$ countries used in the study, classified according to the United Nations geoscheme (UN M49 standard)*.

```{r, message = F}
library("sf")
# using new geographic 
source(file = "data/Load_Geospatial_Data.R")
sf_use_s2(F)
world_sf <- GeoDATA %>%
  rename(region = SIREGION, iso3 = ISO3)
countries_regions <- world_sf %>%
  rmapshaper::ms_simplify(, keep = 0.05, keep_shapes = T)
# polygons with same country than UN data basis
world <- st_transform(countries_regions, my_proj)
world_union <- st_union(world)

# contours, longitude and latitude of the map
p1 <- rbind(c(-180, -90), 
            c(180, -90),
            cbind(180, seq(-90, 90, by = 1)),
            c(180, 90),
            c(-180, 90),
            cbind(-180, seq(90, -90, by = -1)),
            c(-180, -90))
border_sf <- st_sfc(st_polygon(list(p1)))
long_sf <- st_sfc(st_linestring(cbind(-150, seq(-90, 90, by = 1))),
                  st_linestring(cbind(-120, seq(-90, 90, by = 1))),
                  st_linestring(cbind(-90, seq(-90, 90, by = 1))),
                  st_linestring(cbind(-60, seq(-90, 90, by = 1))),
                  st_linestring(cbind(-30, seq(-90, 90, by = 1))),
                  st_linestring(cbind(0, seq(-90, 90, by = 1))),
                  st_linestring(cbind(150, seq(-90, 90, by = 1))),
                  st_linestring(cbind(120, seq(-90, 90, by = 1))),
                  st_linestring(cbind(90, seq(-90, 90, by = 1))),
                  st_linestring(cbind(60, seq(-90, 90, by = 1))),
                  st_linestring(cbind(30, seq(-90, 90, by = 1)))
)
lat_sf <- st_sfc(st_linestring(cbind(seq(-180, 180, by = 1), -60)),
                  st_linestring(cbind(seq(-180, 180, by = 1), -30)),
                  st_linestring(cbind(seq(-180, 180, by = 1), -0)),
                  st_linestring(cbind(seq(-180, 180, by = 1), 30)),
                  st_linestring(cbind(seq(-180, 180, by = 1), 60))
)
# Coordinate Reference System
st_crs(border_sf) <- 4326
st_crs(long_sf) <- 4326
st_crs(lat_sf) <- 4326
border_sf <- st_transform(border_sf, my_proj)
long_sf <- st_transform(long_sf, my_proj)
lat_sf <- st_transform(lat_sf, my_proj)
sea <- st_difference(border_sf, world_union)
```

```{r}
# sahara
world_iso_3_agg <- world
world_iso_3_agg$iso3[world_iso_3_agg$iso3 == "ESH"] <- "MAR"
world_iso_3_agg <- aggregate(world_iso_3_agg[, "iso3"], 
          by = list(iso3 = world_iso_3_agg$iso3),
          FUN = length)
# fontiere Maroc / Sahara 
frontiers <- st_intersection(world[world$iso3 == "MAR", ], 
                world[world$iso3 == "ESH", ])
```


```{r, fig.width = 10, fig.height = 6}
world_iso_3_plot <- merge(world_iso_3_agg, 
    st_drop_geometry(world)[, c("iso3", "SREGION")], by = "iso3")
#world_iso_3_plot[is.na(world_iso_3_plot$SREGION), ]$SREGION <- 
#  c("Sub-Saharan Africa", "Antarctica", "Southern Asia")
world_iso_3_plot %>%
  ggplot() +
  geom_sf(aes(fill = SREGION)) +
  geom_sf(data = frontiers, linetype = "21", linewidth = 0.1) +
  theme(legend.position = "bottom") + 
  labs(fill = "Regional \n groupings")
# ggsave(filename = "figures/world.pdf", width = 10, height = 6)
```


We provide the code used to generate the figure titled  *Left: Location of MERRA-2 grid cells (with resolution $0.625^\circ \times 0.5^\circ$) around Switzerland. Right: Zoomed-in view of the grid cells surrounding the city of Geneva.*

```{r, message = F, warning = F}
require(sf)
bb <- st_as_sfc(st_bbox(c(xmin = -5,
                          ymin = 40,
                          xmax = 15, 
                          ymax = 53), 
                        crs = st_crs(4326)))

temp<- st_intersection(all_cells, st_transform(bb, st_crs(all_cells)))
nc_osm <- get_tiles(CH_zoom, provider = "Esri.WorldShadedRelief", 
                      zoom = 10, crop = F)

# pdf(file = "figures/CH.pdf", width = 10, height = 4)
par(oma = c(0, 0, 0, 0), mar = c(0, 1, 0, 1), mfrow = c(1, 2))
plot(st_geometry(temp)) # , border = "white")
temp_1 <- st_intersection(world_union, st_transform(bb, st_crs(all_cells)))
plot(st_geometry(temp_1), add = T)
temp_2 <- st_intersection(sea, st_transform(bb, st_crs(all_cells)))
plot(temp_2, col = "lightblue", border = rgb(0.2, 0.2, 0.2), add = T)
plot(st_geometry(temp), border = "grey", add = T)
plot(st_geometry(geneva_cell), add = T, border = "red")
plot(st_transform(geneva, st_crs(nc_osm)), add = T, pch = 16, col = "red")

plot_tiles(nc_osm, axes = T)
plot(st_geometry(CH), add = T, lty = 2)
plot(st_geometry(geneva_cell), add = T, border = "red")
plot(st_transform(geneva, st_crs(nc_osm)), add = T, pch = 16, col = "red")
plot(st_geometry(st_transform(st_centroid(CH))), add = T, pch = 3)
legend(460000, 4850000, 
       legend = c("Grid cell", "MERRA-2 grid center", "Geneva city"),
       lty = c(2, NA, NA), pch = c(NA, 3, 16), 
       col = c("black", "black", "red"), bty = "n",
       cex = 0.9)
# dev.off()
```

```{r, warning = F, eval = F}
size_cells <- numeric(nrow(world))
for(k in 1:nrow(world)) {
  size_cells[k] <- nrow(st_intersection(all_cells, world[world$iso3 == world$iso3[k], ]))
    cat(k, " : ", size_cells[k],  "\n")
}
mean(size_cells)
save(size_cells, file = "results/size_cells.RData")
```

```{r, echo = F, message = F, warning = F}
load("results/size_cells.RData")
```

```{r, warning = F, message = F}
ind_intersect_CH <- st_intersects(all_cells, 
              world[world$iso3 == "CHE", ]) %>%
  sapply(function(x) length(x) != 0)

# obtain the contours of CH
cells_suisse <- st_intersection(all_cells,
  world[world$iso3 == "CHE", ])
coords_ch <- cbind(cells_suisse$long, cells_suisse$lat)

cells_suisse_full <- all_cells[ind_intersect_CH, ]

nc_osm <- get_tiles(cells_suisse_full, 
                      provider = "Esri.WorldShadedRelief", 
                      zoom = 7, crop = T)
```


```{r, fig.width = 8, fig.height = 5, message = F, warning = F}
# pdf("figures/temp_suisse.pdf", width = 8, height = 5)
par(oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0))
# map
plot_tiles(nc_osm)
# mf_shadow(cells_suisse, add = T, cex = 0.8)
plot(st_geometry(cells_suisse_full), border = rgb(0.3, 0.3, 0.3), add = T,
     lty = 2)
plot(st_geometry(cells_suisse), border = rgb(0.3, 0.3, 0.3), 
     lwd = 1, add = T)
plot(st_geometry(world[world$iso3 == "CHE", ]), border = "magenta", 
     lwd = 1.3, add = T)
coords_ch_crs <- st_coordinates(st_centroid(cells_suisse_full))
points(coords_ch_crs[, 1], coords_ch_crs[, 2], pch = 3)
geneva <- st_transform(
  st_as_sf(data.frame(long = 6.143158, lat = 46.2044),
            coords = c("long", "lat"), crs = 4326), 
  st_crs(nc_osm)
)
text(st_coordinates(geneva)[, 1], st_coordinates(geneva)[, 2],
     "Geneva", pos = 4, cex = 1.2)
plot(st_transform(geneva, st_crs(nc_osm)), add = T, pch = 16, col = "red")
legend("topright", 
       legend = c("MERRA-2 grid center", "Grid cell", "Switzerland"),
       lty = c(NA, 1, 1), pch = c(3, NA, NA), 
       col = c("black", "black", "magenta"), bty = "n")
# dev.off()
```



### Population data

To compute population-weighted country-level climate indicators, we rely on the LandScan Global dataset (https://landscan.ornl.gov), which provides annual gridded estimates of ambient population at a fine spatial resolution (approximately 1 $km^2$, or $21{,}600 \times 43{,}200$ globally) from 2000 to 2023. Let 
$\text{Pop}_{k,t}$ denote the estimated population in grid cell $k$ in year $t$, where $k\in\{1,\ldots,K\}$ indexes the LandScan grid cells, with $K=21{,}600 \times 43{,}200=933{,}120{,}000$.

We use the **raster** package to import the data and then provide the code used to generate the figure titled Exploratory analysis of daily temperature and precipitation at the Geneva grid cell ($s = \text{Geneva}$) for the year 2024. This figure includes (left) daily time series of maximum, mean, and minimum temperatures (top row) and daily precipitation (bottom row); (middle) kernel density estimates; and (right) empirical cumulative distribution functions (ECDFs), offering a comprehensive summary of both temporal dynamics and distributional properties.


```{r, warning = F, message = F}
library(terra)
temp <- terra::rast(paste0("data/landscan-global-2023-colorized.tif"))

m <- rbind(c(255, 255, 190, 255), 
           c(255, 255, 115, 255),
           c(255, 255, 0, 255), 
           c(255, 170, 0, 255), 
           c(255, 102, 0, 255), 
           c(255, 0, 0, 255), 
           c(204, 0, 0, 255), 
           c(115, 0, 0, 255) )
my_min <- c(1, 6, 26, 51, 101, 501, 2501, 5001)
my_max <- c(5, 25, 50, 100, 500, 2500, 5000, 185000)
my_mean <- (my_min + my_max) / 2 # could be improved
r_mean <- subst(temp, m, my_mean)

# obtain the population data in CH
# select one country 
temp_cnty <- world_sf[which(world_sf$M49_CODE == "756"), ]
temp_cnty <- st_geometry(st_union(st_transform(cells_suisse, st_crs(temp_cnty))))
cm_mean <- crop(r_mean, vect(temp_cnty), mask=T)
```



```{r, fig.width = 10, fig.height = 6, message = F, warning = F}
#pdf("figures/temp_suisse_pop.pdf", width = 10 * 0.8, height = 6*0.8)
par(oma = c(0, 0, 0, 0), mar = c(4, 4, 1, 1), mgp = c(2.5, 1, 0), las = 1)
# population 
plot(cm_mean, axes = F)
plot(st_geometry(st_transform(cells_suisse, st_crs(temp_cnty))), add = T, 
     border = rgb(0.7, 0.7, 0.7), lwd = 1.2)
plot(st_geometry(st_union(st_transform(cells_suisse, st_crs(temp_cnty)))), 
     add = T, border = "magenta", lwd = 2)
geneva <- st_transform(
  st_as_sf(data.frame(long = 6.143158, lat = 46.2044),
            coords = c("long", "lat"), crs = 4326), 
  st_crs(temp_cnty)
)
text(st_coordinates(geneva)[, 1], st_coordinates(geneva)[, 2],
     "Geneva", pos = 4, cex = 1.2)
plot(geneva, add = T, pch = 16, col = "red")
text(10.15, 47.6, "Pop. (Landscan \n grid cell)", cex = 0.)
legend("topleft", 
       legend = c("MERRA-2 grid cell", "Switzerland"),
       lty = c(1, 1), pch = c(NA, NA), 
       col = c("black", "magenta"), bty = "n")
#dev.off()
```



# From daily grid observations to annual country-level indicators


## Temporal aggregation at the grid level

We provide the code used to produce the figure titled *Daily precipitation in 2024 and derived precipitation-based indicators for the Geneva grid cell. This plot highlights key precipitation metrics, including the longest dry spell ($Dry$), the longest wet spell ($Wet$), and the maximum 5-day cumulative precipitation ($P5D$)*.


```{r, message = F, warning = F}
all_suisse <- dir("data/suisse/")
cell_suisse <- vector("list", length(all_suisse))
#my_pal <- pals::polychrome(length(all_suisse))
my_mean <- numeric(length(all_suisse))
for(k in 1:length(all_suisse)) {
  cell_suisse[[k]] <- read.table(paste0("data/suisse/", all_suisse[k]),
     header = F, sep = ";",
     colClasses = c("character", "numeric", "numeric", "numeric", "numeric"),
     col.names = c("YYYYMMDD", "T2MMEAN", "T2MMIN", "T2MMAX", "PRECTOTCORR")) %>%
    filter(substr(YYYYMMDD, 1, 4) >= "2024")
  cell_suisse[[k]]$YYYYMMDD <- as.Date(cell_suisse[[k]]$YYYYMMDD)
  my_mean[k] <- mean(cell_suisse[[k]]$T2MMEAN) 
}

sum_5days <- numeric(length(cell_suisse))
consecutive_days_wet <- numeric(length(cell_suisse))
consecutive_days_dry <- numeric(length(cell_suisse)) 

for(k in 1:length(cell_suisse)) {
# dry 
  temp_days_dry <- cell_suisse[[k]] %>% 
      group_by(grp = cumsum(PRECTOTCORR > 1), year = substr(YYYYMMDD, 1, 4)) %>%
      filter(PRECTOTCORR <= 1) %>% 
      summarise(start_date = min(YYYYMMDD),
                end_date = max(YYYYMMDD),
                days_con = n()) %>% 
      dplyr::select(-grp) %>%
      group_by(year) %>%
      summarise(my_max = max(days_con)) 
  consecutive_days_dry[[k]] = temp_days_dry$my_max    
  # wet
  temp_days_wet <- cell_suisse[[k]] %>% 
      group_by(grp = cumsum(PRECTOTCORR <= 1), year = substr(YYYYMMDD, 1, 4)) %>%
      filter(PRECTOTCORR > 1) %>% 
      summarise(start_date = min(YYYYMMDD),
                end_date = max(YYYYMMDD),
                days_con = n()) %>% 
      dplyr::select(-grp) %>%
      group_by(year) %>%
      summarise(my_max = max(days_con)) 
  consecutive_days_wet[[k]] =  temp_days_wet$my_max    
  
  # 5-days-precipitation and maximum observed during the precipitations 
  n_year <- nrow(cell_suisse[[k]])
  sum_5days[k] <- max(cell_suisse[[k]]$PRECTOTCORR +
      c(0, cell_suisse[[k]]$PRECTOTCORR)[-c(n_year)] +
      c(0, 0, cell_suisse[[k]]$PRECTOTCORR)[-c((n_year-1):n_year)] +
      c(0, 0, 0, cell_suisse[[k]]$PRECTOTCORR)[-c((n_year-2):n_year)] +
      c(0, 0, 0, 0, cell_suisse[[k]]$PRECTOTCORR)[-c((n_year-3):n_year)]) 

}
```

```{r, fig.width = 10, fig.height = 5}
days_x <- 1:366
deb_month <-  c(1, 32, 61, 92, 122, 153, 183, 214, 245, 275, 306, 336)
month.name <- paste0(month.abb, " 1 \n (d=", deb_month, ")")
#pdf(file = "figures/prec.pdf", width = 10, height = 6)
par(las = 1, mar = c(4, 4, 0.2, 0.2), mgp = c(2.7, 1, 0))
plot(days_x, cell_suisse[[1]]$PRECTOTCORR, type = "h",
       col = "grey", lwd = 1, xaxt = "n",
     xlab = "Day of the year",
     ylab = "Precipitation (in mm)")
axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)

abline(h = 1, lwd = 1.5, lty = 2)

arrows(302, 2, 322, 2, lwd = 1,length = 0.05, code = 3)
text((302+322) / 2, 5, "Consecutive \n  dry days")

arrows(141, 10, 148, 10, lwd = 1,length = 0.05, code = 3)
text((141+148) / 2, 12, "Consecutive \n wet days")

arrows(244, 31, 249, 31, lwd = 1,length = 0.05, code = 3)
text((244 + 249) / 2, 32, "Max 5-days precipitation")

legend("topleft", legend = c(TeX(r'($P_{Geneva, d, 2024}$)'), 
                             "Threshold (1mm)"), 
       lty = c(1, 2), col = c("grey", "black"))
#dev.off()
```

We provide the code used to generate the figure titled *Spatial distribution of precipitation-based indicators ($Dry$, $Wet$, and $P5D$) in 2024 for MERRA-2 grid cells overlapping with Switzerland. These cell-level values serve as the basis for the subsequent aggregation of climate indicators at the national level.*


```{r, fig.width = 8, fig.height = 5.5, warning = F}
#pdf("figures/prec_ind_CH.pdf", width = 12*0.75, height = 8*0.75)
par(mfrow = c(2, 2), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0))
pal_cdd <- RColorBrewer::brewer.pal(5, "YlOrRd")
bk_cdd <- round(classInt::classIntervals(consecutive_days_dry, 5, "kmeans")$brks,
            digits = 6)
ind_cdd <- findInterval(consecutive_days_dry, bk_cdd, all.inside = TRUE)
    
plot_tiles(nc_osm)
plot(st_geometry(cells_suisse_full), add = T, lty = 2, border = "darkgrey")
plot(st_geometry(cells_suisse), border = rgb(0.5, 0.5, 0.5), lwd = 0.4, add = T,
     col = scales::alpha(pal_cdd[ind_cdd], 0.4))
plot(st_geometry(st_centroid(cells_suisse_full)), add = T, pch = 3, 
     col = colorspace::darken(pal_cdd[ind_cdd], amount = 0.2) )
plot(st_geometry(st_union(cells_suisse)), 
     add = T, border = "magenta", lwd = 2)
maplegend::leg(type = "choro", val = bk_cdd, pos = "topleft", 
                 pal = pal_cdd, val_rnd = 1, title = "Dry")

# consecutive_days_wet
pal1 <- RColorBrewer::brewer.pal(5, "YlGnBu")
bk <- round(classInt::classIntervals(consecutive_days_wet, 5, "kmeans")$brks,
            digits = 6)
ind <- findInterval(consecutive_days_wet, bk, all.inside = TRUE)
    
plot_tiles(nc_osm)
plot(st_geometry(cells_suisse_full), add = T, lty = 2, border = "darkgrey")
plot(st_geometry(cells_suisse), border = rgb(0.5, 0.5, 0.5), lwd = 0.4, add = T,
     col = scales::alpha(pal1[ind_cdd], 0.4))
plot(st_geometry(st_centroid(cells_suisse_full)), add = T, pch = 3, 
     col = colorspace::darken(pal1[ind_cdd], amount = 0.2) )
plot(st_geometry(st_union(cells_suisse)), 
     add = T, border = "magenta", lwd = 2)
maplegend::leg(type = "choro", val = bk, pos = "topleft", 
                 pal = pal1, val_rnd = 1, title = "Wet")

# P5D
pal1 <- RColorBrewer::brewer.pal(5, "YlGnBu")
bk <- round(classInt::classIntervals(sum_5days, 5, "kmeans")$brks, digits = 6)
ind <- findInterval(sum_5days, bk, all.inside = TRUE)
    
plot_tiles(nc_osm)
plot(st_geometry(cells_suisse_full), add = T, lty = 2, border = "darkgrey")
plot(st_geometry(cells_suisse), border = rgb(0.5, 0.5, 0.5), lwd = 0.4, add = T,
     col = scales::alpha(pal1[ind_cdd], 0.4))
plot(st_geometry(st_centroid(cells_suisse_full)), add = T, pch = 3, 
     col = colorspace::darken(pal1[ind_cdd], amount = 0.2) )
plot(st_geometry(st_union(cells_suisse)), 
     add = T, border = "magenta", lwd = 2)
maplegend::leg(type = "choro", val = bk, pos = "topleft", 
                 pal = pal1, val_rnd = 3, title = "P5D")

plot(0, 0, type = "n", xaxt = "n", yaxt = "n", xlab = "", ylab = "",
     bty = "n")
legend("topleft", 
       legend = c("MERRA-2 grid center", "Grid cell", "Switzerland"),
       lty = c(NA, 1, 1), pch = c(3, NA, NA), 
       col = c("black", "black", "magenta"), bty = "n")

#dev.off()
```


## Aggregation of grid-level climate indicators to the country level

We provide the code used to generate the figure titled *Left panel: National boundaries of Switzerland (in black) with a surrounding buffer of $0.625^\circ$, corresponding to the spatial resolution of the MERRA-2 grid. Right panel: $Dry$ indicator interpolated onto the LandScan population grid using bilinear interpolation.*


 
```{r, message = F, warning=F}
load("results/my_grid_final.RData")
```


```{r, message = F, warning=F}
my_grid_sf <- st_as_sf(my_grid, coords = c("long", "lat"), 
                       crs = 4326)

ind_intersect_CH_buffer <- st_intersects(my_grid_sf, 
              st_buffer(st_transform(world[world$iso3 == "CHE", ], 4326), 0.625)) %>%
  sapply(function(x) length(x) != 0)

cells_suisse_full_buffer <- my_grid_sf[ind_intersect_CH_buffer, ] %>%
  st_transform(st_crs(world_sf))
coords_ch <- st_coordinates(cells_suisse_full_buffer)
consecutive_days_dry <- cells_suisse_full_buffer$dry_2024
```


```{r, eval = T, echo = T}
# select one country 
temp_cnty <- world_sf[which(world_sf$M49_CODE == "756"), ]

# correspondance between colors and population count
m <- rbind(c(255, 255, 190, 255), 
           c(255, 255, 115, 255),
           c(255, 255, 0, 255), 
           c(255, 170, 0, 255), 
           c(255, 102, 0, 255), 
           c(255, 0, 0, 255), 
           c(204, 0, 0, 255), 
           c(115, 0, 0, 255) )

my_min <- c(1, 6, 26, 51, 101, 501, 2501, 5001)
my_max <- c(5, 25, 50, 100, 500, 2500, 5000, 185000)
my_mean <- (my_min + my_max) / 2 # could be improved

years_select <- "2024"
year_data <- "2023"

# Be careful : Can take time and memory 
# Here we transform value c(255, 255, 190, 255) by 1 (lower bound) and 5 (upper bound), etc.
r_mean <- subst(temp, m, my_mean)
# aggregate by a factor 4 the data 

# rasterize for variables - all years 
cells_suisse_xyz <- data.frame(
  long = coords_ch[, 1], 
  lat = coords_ch[, 2])
cells_suisse_xyz$CDD <- consecutive_days_dry
cells_suisse_xyz$cste <- 1

suisse_cell <- rast(cells_suisse_xyz, type = "xyz")
crs(suisse_cell)  <- "epsg:4326"

# crop the data into the polygon
crop_cells <- crop(suisse_cell, temp_cnty, snap = "out", mask=F)
# crop_cells <- crop(cells_suisse_buffer, temp_cnty, snap = "out", mask=F)
cm_mean <- crop(r_mean, temp_cnty, mask=F)
  
# we keep the cells falling into the polygon
my_sample <- terra::resample(crop_cells, cm_mean)
my_sample <- crop(my_sample, temp_cnty, mask=T)
```

We provide the code used to generate the figure titled: *Left panel: National boundaries of Switzerland (in black) with a surrounding buffer of $0.625^\circ$, corresponding to the spatial resolution of the MERRA-2 grid. Right panel: $Dry$ indicator interpolated onto the LandScan population grid using bilinear interpolation.* 

```{r, fig.width = 10, fig.height = 4, warning= F, message = F }
bk_cdd <- round(classInt::classIntervals(consecutive_days_dry, 5, "kmeans")$brks,
            digits = 6)
ind_cdd <- findInterval(consecutive_days_dry, bk_cdd, all.inside = TRUE)
    
#pdf("figures/pop_cdd.pdf", width = 10, height = 4)
par(oma = c(0, 0, 0, 0), mar = c(1, 1, 0.5, 0.5), mfrow = c(1, 2))
# Buffer
plot(st_geometry(st_buffer(st_transform(world[world$iso3 == "CHE", ], 4326), 0.625)))
plot(st_geometry(st_transform(world[world$iso3 == "CHE", ], 4326)), 
     add = T)
plot(st_geometry(cells_suisse_full_buffer), add = T)

# Interpolation
plot(coords_ch[, 1], coords_ch[, 2], pch = 3, 
       col = colorspace::darken(pal_cdd[ind_cdd], amount = 0.3), 
     xaxt = "n", yaxt = "n", bty = "n", xlab = "", ylab = "")
plot(my_sample[[1]], breaks = bk_cdd, col = scales::alpha(pal_cdd, 0.6),
     legend = F, add = T)

plot(st_geometry(st_transform(cells_suisse_full, 4326)), add = T, 
     border = "grey", lty = 2, lwd = 0.8)

plot(st_geometry(temp_cnty), add = T )

maplegend::leg(type = "choro", val = bk_cdd, pos = "topleft", 
                 pal = pal_cdd, val_rnd = 1, title = "Dry")

# dev.off()
# nearest neighbours between 
if(length(table(cm_mean[, , 1])) == 0) {
    cm_mean[, , 1] <- 1
}
nn <- terra::zonal(my_sample, cm_mean, "sum", na.rm=TRUE)

nb_habitant <- sum(nn$lyr1 * nn$cste) # sum(temp_pop * as.numeric(names(temp_pop)), na.rm = T)

temp_res <- sapply(nn["CDD"], function(x) sum(x * nn$lyr1, na.rm = T) / nb_habitant)
#dev.off()
```

```{r, echo = F}
load("results/final_indicator.RData")
```

We provide the code used to generate the figure titled: *Population-weighted national estimates of the $Dry$ indicator in 2024. Values represent the average number of consecutive dry days experienced by residents of each country, accounting for the spatial distribution of population.* 

```{r, fig.width = 12, fig.height = 7}

vec_temp <- st_drop_geometry(final_indicator)[, "dry_2024"]
bk <- round(classInt::classIntervals(vec_temp, 9, "kmeans")$brks, 
            digits = 6)
bk[1] <- min(vec_temp)
bk[length(bk)] <- max(vec_temp)
pal1 <- RColorBrewer::brewer.pal(9, "Reds")
ind <- findInterval(vec_temp, bk, all.inside = TRUE)
#pdf("figures/world_dry_2024.pdf", width = 12 * 0.8, height = 6.7 * 0.8)      
par(mar = c(0, 1, 1, 0))
plot(st_geometry(world), col = pal1[ind], 
         border = pal1[ind], pch = 15, cex = 0.5, lwd = 0.1)
plot(st_geometry(world_iso_3_agg), border = "lightgrey",
     lwd = 0.05, add = T)
# title("Consecutive Dry Day in 2024", line = -1.15)
plot(sea, col = scales::alpha("lightblue", 0.3), 
     border = rgb(0.2, 0.2, 0.2), add = T)
plot(st_geometry(world_union), add = T, border = rgb(0.2, 0.2, 0.2))
plot(long_sf, add = T, col = "lightgrey")
plot(lat_sf, add = T, col = "lightgrey")

## parameters for legend
    poly_leg_temp <- vector("list", length(bk) - 1)
    for(k in 1:(length(bk) - 1)) {
      poly_leg_temp[[k]] <- rbind(c(-12000000 + (k - 1) * 2750000, 9200000), 
                              c(-12000000 + 1000000 + (k - 1) * 2750000, 9200000),
                              c(-12000000 + 1000000 + (k - 1) * 2750000, 8900000),
                              c(-12000000 + (k - 1) * 2750000, 8900000),
                              c(-12000000 + (k - 1) * 2750000, 9200000))
    }
    poly_leg <- st_sfc(st_polygon(poly_leg_temp[1]))
    for(k in 2:length(poly_leg_temp)) {
      poly_leg <- c(poly_leg, st_sfc(st_polygon(poly_leg_temp[k])))
    }
# legend
plot(poly_leg, col = pal1, add = T)
    temp_coord <- st_coordinates(st_centroid(poly_leg))
    bk_round <- round(bk, 1)
    for(k in 1:length(poly_leg)) {
      if(k == 1) {
        my_text <- paste0("<", bk_round[2])
        } else {
          if(k == (length(bk) - 1)) {
            my_text <- paste0(">=", bk_round[length(bk) - 1])
            } else {
              my_text <- paste0("[", bk_round[k], "; ", bk_round[k+1], "[")
            }
        }
      text(temp_coord[k, 1], temp_coord[k, 2] + 10, my_text, pos = 3, cex = 0.7)
    }
    title("Consecutive Dry Days in 2024")
 # dev.off()
```



# Construction of conventional climate indicators

We provide the code used to generate the figure titled: *Top panels: Daily temperature series for the Geneva grid cell ($s = \text{Geneva}$) from 1981 to 2024, shown in black for (left) maximum temperature $T^{\text{MAX}}_{\text{Geneva},d,t}$, (center) mean temperature $T^{\text{MEAN}}_{\text{Geneva},d,t}$, and (right) minimum temperature $T^{\text{MIN}}_{\text{Geneva},d,t}$. The red dashed line represents the corresponding reference climatology $T^{\text{type}}_{\text{Geneva},\,\text{ref}}$ computed over the 1981–2010 baseline. Bottom panels: Focus on the year 2024, with daily values $T^{\text{type}}_{\text{Geneva},d,2024}$ shown in grey, their annual average $\bar{T}^{\text{type}}_{\text{Geneva},2024}$ as a dotted line, and the reference value $T^{\text{type}}_{\text{Geneva},\,\text{ref}}$ again in red dashed. This visualization allows for direct interpretation of the temperature anomaly $\Delta T^{\text{type}}_{\text{Geneva},2024}$.*

```{r, fig.width = 11, fig.height = 6}
obs_year <- 2024
temp_geneva <- read.table(paste0("data/suisse/", all_suisse[1]),
                        header = F, sep = ";", 
                        colClasses = c("character", "numeric", "numeric",
                                       "numeric", "numeric"),
                        col.names = c("YYYYMMDD", "T2MMEAN", "T2MMIN", "T2MMAX",
                                      "PRECTOTCORR")) 
temp_geneva$YYYYMMDD <- as.Date(temp_geneva$YYYYMMDD)
temp_geneva_filter <- temp_geneva %>%
  filter(substr(YYYYMMDD, 1, 4) < "2011")
temp_geneva_year <- temp_geneva %>%
  filter(substr(YYYYMMDD, 1, 4) > obs_year - 1 & 
           substr(YYYYMMDD, 1, 4) <= obs_year)
date_year <- temp_geneva_year$YYYYMMDD
date_year <- 1:length(date_year)

#pdf("figures/mean_temperatures.pdf", width = 11 * 0.8, height = 6* 0.8)
par(las = 1, oma = c(0, 0, 0, 0), mar = c(4, 3.5, 0.5, 0.5),
    mfrow = c(2, 3), mgp = c(2.1, 1, 0))

# Normal Temperatures
# Max 
temp_normal_cell_t2max <- mean(temp_geneva_filter$T2MMAX)
plot(temp_geneva_filter$YYYYMMDD, temp_geneva_filter$T2MMAX, 
     type = "l", xlab = "Years", ylab = "Temperature (in degree C)", 
     lwd = 0.8, 
     ylim = c(-25, 35))
abline(h = temp_normal_cell_t2max, lty = 2, col = "red")
legend("bottomright", 
       legend = c(TeX(r'($T_{Geneva,d,t}^{MAX}$)'),
                  TeX(r'($T_{Geneva, ref}^{MAX}$)')), 
       lty = c(1, 2), col = c("black", "red"), cex = 0.9)
# Mean 
temp_normal_cell_t2m <- mean(temp_geneva_filter$T2MMEAN)
plot(temp_geneva_filter$YYYYMMDD, temp_geneva_filter$T2MMEAN, 
     type = "l", xlab = "Years", ylab = "Temperature (in degree C)", 
     lwd = 0.8, 
     ylim = c(-25, 35))
abline(h = temp_normal_cell_t2m, lty = 2, col = "red")
legend("bottomright", legend = 
         c(TeX(r'($T_{Geneva,d,t}^{MEAN}$)'), 
           TeX(r'($T_{Geneva, ref}^{MEAN}$)')), 
       lty = c(1, 2), col = c("black", "red"), cex = 0.9)
# Min 
temp_normal_cell_t2min <- mean(temp_geneva_filter$T2MMIN)
plot(temp_geneva_filter$YYYYMMDD, temp_geneva_filter$T2MMIN, 
     type = "l", xlab = "Years", ylab = "Temperature (in degree C)", 
     lwd = 0.8, 
     ylim = c(-25, 35))
abline(h = temp_normal_cell_t2min, lty = 2, col = "red")
legend("bottomright", legend = 
         c(TeX(r'($T_{Geneva,d,t}^{MIN}$)'), 
           TeX(r'($T_{Geneva, ref}^{MIN}$)')), 
       lty = c(1, 2), col = c("black", "red"), cex = 0.9)

# Differences
##################################################
# Max
mean_year_t2max <- mean(temp_geneva_year$T2MMAX)
month.name_2 <- paste0(month.abb, " 1 (d=", deb_month, ")")

plot(date_year, temp_geneva_year$T2MMAX, type = "l", 
       ylab = "Temperature (in degree C)", 
     xlab = "",
     col = rgb(0, 0, 0, alpha = 0.3), xaxt = "n", 
     ylim = c(-12, 35))

axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name_2, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)

abline(h = mean_year_t2max, lty = 3)
abline(h = temp_normal_cell_t2max, lty = 2, col = "red")

arrows(10, mean_year_t2max, 10, temp_normal_cell_t2max, lwd = 0.7,
               length = 0.025, code = 3)
text(10, (mean_year_t2max + temp_normal_cell_t2max) / 2, 
    TeX(r'($\Delta T_{Geneva, 2024}^{MAX}$)'), pos = 4)

# legend
legend("topleft", legend = c(TeX(r'($T_{Geneva, Ref}^{MAX}$)'), 
                             TeX(r'($T_{Geneva,d,2024}^{MAX}$)'), 
                             TeX(r'($\bar{T}_{Geneva, 2024}^{MAX}$)')),
       col = c("red", "grey", "black"), lty = c(2, 1, 3), cex = 0.9)
# Mean
mean_year_t2m <- mean(temp_geneva_year$T2MMEAN)
plot(date_year, temp_geneva_year$T2MMEAN, type = "l",  
      ylab = "Temperature (in degree C)", 
     xlab = "",
     col = rgb(0, 0, 0, alpha = 0.3), xaxt = "n", 
     ylim = c(-12, 35))

axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name_2, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)

abline(h = mean_year_t2m, lty = 3)
abline(h = temp_normal_cell_t2m, lty = 2, col = "red")

arrows(10, mean_year_t2m, 10, temp_normal_cell_t2m, lwd = 1,
               length = 0.025, code = 3)
text(10, (mean_year_t2m + temp_normal_cell_t2m) / 2, 
     TeX(r'($\Delta T_{Geneva, 2024}^{MEAN}$)'), pos = 4)

# legend
legend("topleft", legend = c(TeX(r'($T_{Geneva, Ref}^{MEAN}$)'), 
                             TeX(r'($T_{Geneva,d,2024}^{MEAN}$)'), 
                             TeX(r'($\bar{T}_{Geneva, 2024}^{MEAN}$)')),
       col = c("red", "grey", "black"), lty = c(2, 1, 3), cex = 0.9)

# Min
mean_year_t2min <- mean(temp_geneva_year$T2MMIN)
plot(date_year, temp_geneva_year$T2MMIN, type = "l",  
     ylab = "Temperature (in degree C)", 
     xlab = "",
     col = rgb(0, 0, 0, alpha = 0.3), xaxt = "n", 
     ylim = c(-12, 35))

axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name_2, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)

abline(h = mean_year_t2min, lty = 3)
abline(h = temp_normal_cell_t2min, lty = 2, col = "red")

arrows(10, mean_year_t2min, 10, temp_normal_cell_t2min, lwd = 1,
               length = 0.025, code = 3)
text(10, (mean_year_t2min + temp_normal_cell_t2min) / 2, 
     TeX(r'($\Delta T_{Geneva, 2024}^{MIN}$)'), pos = 4)

# legend
legend("topleft", legend = c(TeX(r'($T_{Geneva, Ref}^{MIN}$)'), 
                             TeX(r'($T_{Geneva,d,2024}^{MIN}$)'), 
                             TeX(r'($\bar{T}_{Geneva, 2024}^{MIN}$)')),
       col = c("red", "grey", "black"), lty = c(2, 1, 3), cex = 0.9)
#dev.off()
```




## Annual precipitation anomalies

We provide the code used to generate the figure titled: *Annual cumulative precipitation in Geneva from 1981 to 2024. The blue horizontal line indicates the historical average over the 1981–2010 reference period. The value for 2024 is highlighted in cyan.* 

```{r, fig.width = 10, fig.height = 5.5}
my_sum <- sum(temp_geneva_year$PRECTOTCORR)
#pdf("figures/diff_prec.pdf", width = 10, height = 5.5)
par(las = 1, oma = c(0, 0, 0, 0), mar = c(4, 4, 1, 1), mgp = c(2.8, 1, 0))
plot(cumsum(temp_geneva_year[, "PRECTOTCORR"]), type = "l", 
     xlab = "Day of the year",
     ylab = TeX("Cumulative precipitation (in mm)"),
     ylim = c(0, 1500), col = "grey", lwd = 0.3, xaxt = "n")
axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)
for(k in 1982:2010) {
  temp_prec <- temp_geneva %>%
    filter(substr(YYYYMMDD, 1, 4) == k) 
  lines(cumsum(temp_prec[, "PRECTOTCORR"]), col = "grey", lwd = 0.3)
  my_sum <- c(my_sum, sum(temp_prec$PRECTOTCORR))
}
abline(h = mean(my_sum), col = "blue", lty = 2)

legend("topleft", legend = c(
  TeX(r'($CumP_{Geneva,d,t}$ for $t \in [1981;2023]$)'), 
  TeX(r'($P_{Geneva,ref}$)'), 
  TeX(r'($CumP_{Geneva,d,2024}$)')
),
lty = c(1, 2, 1), 
col = c("grey", "blue", "cyan"),
lwd = c(0.3, 1, 1))
temp_prec <- temp_geneva %>%
    filter(substr(YYYYMMDD, 1, 4) == 2024)
lines(cumsum(temp_prec[, "PRECTOTCORR"]), col = "cyan")

arrows(366, mean(my_sum), 366, sum(temp_prec[, "PRECTOTCORR"]), lwd = 1,
               length = 0.025, code = 3)
text(366, (mean(my_sum) + sum(temp_prec[, "PRECTOTCORR"])) / 2, 
     TeX(r'($\Delta P_{Geneva, 2024}$)'), pos = 2)
#dev.off()
```



## Heatwave Indicator (GHWR)


We provide the code used to generate the figure titled: *Daily $T^{\text{MAX}}$ values in Delhi for the year 2024. The heatwave runs (days contributing to the GHWR indicator) are highlighted in red.*

```{r, fig.width = 12, fig.height = 6}
coords_delhi <- c(LON = 77.500, LAT = 28.5)
ind_delhi <- which(my_grid[, 1] == coords_delhi["LON"] & 
                  my_grid[, 2] == coords_delhi["LAT"])
temp_delhi <- read.table("data/cell_136925.csv", header = FALSE, sep = ";", 
                         colClasses = c("character", "numeric", "numeric",  
                                        "numeric", "numeric"),
                         col.names = c("YYYYMMDD","T2MMEAN", "T2MMIN", "T2MMAX",
                                       "PRECTOTCORR")) %>% 
  filter(substr(YYYYMMDD, 1, 4) == "2024")
temp_observed_t2max <- as.numeric(temp_delhi$T2MMAX)
date_year <- 1:366
#pdf(file = "figures/ghwr_35.pdf", width = 10, height = 5.5)
par(las = 1, oma = c(0, 0, 0, 0), mar = c(3.7, 3.6, 1, 1), mgp = c(2.5, 1, 0))
##################################################
plot(date_year, temp_observed_t2max, type = "l", 
     ylim = range(temp_observed_t2max),
     col = "grey", lty = 2, xaxt = "n", xlab = "Day of the year",
     ylab = "Temperature (in degree C)")

axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)

ind_upp <- which(temp_observed_t2max > 35)
abline(h = 35, lty = 3, col = "darkred")
# legend
legend("topleft", legend = c(TeX(r'($T_{Delhi, d, 2024}^{MAX}$)'), 
                             "Heatwave runs", "Threshold (35°C)"),
       lty = c(2, 1, 3), col = c("grey", "red", "darkred"),
       lwd = c(1, 2, 1))
# print the values up to the upper bound
ind_to_print <- vector("list", 0)
nb_suit <- 1
temp <- 1
for(k in 2:length(ind_upp)) {
  if(ind_upp[k] - ind_upp[k-1] == 1) {
    temp <- temp + 1
  } else {
    if (temp >= 5) {
      ind_to_print[[nb_suit]] <- ind_upp[(k-temp):(k-1)]
      temp <- 1
      lines(date_year[ind_to_print[[nb_suit]]], temp_observed_t2max[ind_to_print[[nb_suit]]], 
            lwd = 2, col = "red")
      nb_suit <- nb_suit + 1
    }
    temp <- 1
  }
}
#dev.off()
```





# Threshold-based indicators of temperature extremes

We provide the code used to compute extremiles (via the `extremile_L` function) and expected shortfall (via the `ES` function). The function `compute_normal` returns, for a given grid cell name, the daily quantile-, extremile-, and expected shortfall-based thresholds for all days $d$ of the year, evaluated at both $\tau = 0.1$ and $\tau = 0.9$.

```{r, message = F}
# function which computes extremiles
extremile_L <- function(y, vec_tau) {
  # y is the vector of observations
  # tau is a vector of values of tau
  # verification
  stopifnot(any(vec_tau > 0), any(vec_tau < 1))
  # initialization
  y <- na.omit(y)
  n <- length(y)
  size_res <- length(vec_tau)
  y_sort <- sort(y)
  # we compute 
  res <- numeric(size_res)
  seq_t <- (0:n) / n 
  for (k in 1:size_res) {
    if (vec_tau[k] < 0.5) {
      s_tau <- log(0.5) / log(1 - vec_tau[k])
      K_tau <- 1 - (1 - seq_t) ^ s_tau 
    } else {
      s_tau <- log(0.5) / log(vec_tau[k])
      K_tau <- seq_t ^ s_tau
    }
    res[k] <- sum(diff(K_tau) * y_sort)
  }
  res
}

# function which computes expected shortfall
ES <- function(y, vec_tau) {
  # y is the vector of observations
  # tau is a vector of values of tau
  # verification
  stopifnot(any(vec_tau > 0), any(vec_tau < 1))
  # initialization
  n <- length(y)
  size_res <- length(vec_tau)
  y_sort <- sort(y)
  # we compute 
  res <- numeric(size_res)
  for (k in 1:size_res) {
    if(vec_tau[k] > 0.5)
      res[k] <- mean(y_sort[ceiling(vec_tau[k] * n):n])
    else
      res[k] <- mean(y_sort[1:ceiling(vec_tau[k] * n)])      
  }
  res
}

# function which computes normal climate for one cell
compute_normal <- function(vec_z) {
  size_z <- length(vec_z)
  
  # final results 
  my_quantile_upp_t2m <- data.frame(
    LON = unique_nom_file$long[as.numeric(vec_z)],
    LAT = unique_nom_file$lat[as.numeric(vec_z)]
  )
  
  my_days <- c(paste0("01-", ifelse(nchar(1:31) == 1, paste0("0", 1:31), 1:31)),
               paste0("02-", ifelse(nchar(1:29) == 1, paste0("0", 1:29), 1:29)),
               paste0("03-", ifelse(nchar(1:31) == 1, paste0("0", 1:31), 1:31)),
               paste0("04-", ifelse(nchar(1:30) == 1, paste0("0", 1:30), 1:30)),
               paste0("05-", ifelse(nchar(1:31) == 1, paste0("0", 1:31), 1:31)),
               paste0("06-", ifelse(nchar(1:30) == 1, paste0("0", 1:30), 1:30)),
               paste0("07-", ifelse(nchar(1:31) == 1, paste0("0", 1:31), 1:31)),
               paste0("08-", ifelse(nchar(1:31) == 1, paste0("0", 1:31), 1:31)),
               paste0("09-", ifelse(nchar(1:30) == 1, paste0("0", 1:30), 1:30)),
               paste0("10-", ifelse(nchar(1:31) == 1, paste0("0", 1:31), 1:31)),
               paste0("11-", ifelse(nchar(1:30) == 1, paste0("0", 1:30), 1:30)),
               paste0("12-", ifelse(nchar(1:31) == 1, paste0("0", 1:31), 1:31)))
  
  my_quantile_upp_t2m[, my_days] <- 0
  row.names(my_quantile_upp_t2m) <- vec_z
  my_quantile_upp_t2max <- my_quantile_low_t2min <- my_quantile_low_t2m <- 
    my_extremile_upp_t2max <- my_extremile_low_t2min <- my_extremile_low_t2m <- my_extremile_upp_t2m <- 
    my_ES_upp_t2max <- my_ES_low_t2min <- my_ES_low_t2m <- my_ES_upp_t2m <- 
    my_quantile_upp_t2m
  
  unique_year <- 1981:2010
  size_year <- length(unique_year)
  
  # the window for each day
  list_window <- vector("list", 366)
  temp_my_days <- c("12-25", "12-26", "12-27", "12-28", "12-29", "12-30", "12-31",
                    my_days,
                    "01-01", "01-02", "01-03", "01-04", "01-05", "01-06", "01-07")
  for(k in 1:366) {
    list_window[[k]] <- temp_my_days[k:(k+14)]
  }
  
  for(z in 1:size_z) {
    # /Users/thibaultlaurent/Documents/ANR_flows/climate_variable/cell/
    temp <- read.table(paste0(my_dir, "/cell_", vec_z[z], ".csv"), header = FALSE, sep = ";", 
                       colClasses = c("character", "numeric", "numeric",  
                                      "numeric", "numeric"),
                       col.names = c("YYYYMMDD","T2MMEAN", "T2MMIN", "T2MMAX",
                                     "PRECTOTCORR"))
    # we keep observations before 2010
    temp <- temp[as.numeric(substr(temp$YYYYMMDD, 1, 4)) <= 2010, ] 
    
    for (i in 1:366) {
      
      # for temperature 
      ind_day <- which(substr(temp$YYYYMMDD, nchar(temp$YYYYMMDD) - 4, nchar(temp$YYYYMMDD)) %in%
                         list_window[[i]])
      
      my_quantile_upp_t2m[z, 2 + i] <- quantile(temp$T2MMEAN[ind_day], 0.9)
      my_quantile_low_t2m[z, 2 + i] <- quantile(temp$T2MMEAN[ind_day], 0.1)
      my_quantile_upp_t2max[z, 2 + i] <- quantile(temp$T2MMAX[ind_day], 0.9)
      my_quantile_low_t2min[z, 2 + i] <- quantile(temp$T2MMIN[ind_day], 0.1)
      
      my_extremile_upp_t2m[z, 2 + i] <- extremile_L(temp$T2MMEAN[ind_day], 0.9)
      my_extremile_low_t2m[z, 2 + i] <- extremile_L(temp$T2MMEAN[ind_day], 0.1)
      my_extremile_upp_t2max[z, 2 + i] <- extremile_L(temp$T2MMAX[ind_day], 0.9)
      my_extremile_low_t2min[z, 2 + i] <- extremile_L(temp$T2MMIN[ind_day], 0.1)
      
      my_ES_upp_t2m[z, 2 + i] <- ES(temp$T2MMEAN[ind_day], 0.9)
      my_ES_low_t2m[z, 2 + i] <- ES(temp$T2MMEAN[ind_day], 0.1)
      my_ES_upp_t2max[z, 2 + i] <- ES(temp$T2MMAX[ind_day], 0.9)
      my_ES_low_t2min[z, 2 + i] <- ES(temp$T2MMIN[ind_day], 0.1)     
    }
  }
  
  # intermediate step 
  return(list(my_quantile_upp_t2m = my_quantile_upp_t2m,
              my_quantile_low_t2m = my_quantile_low_t2m,
              my_quantile_upp_t2max = my_quantile_upp_t2max,
              my_quantile_low_t2min = my_quantile_low_t2min,
              my_extremile_upp_t2m = my_extremile_upp_t2m,
              my_extremile_low_t2m = my_extremile_low_t2m,
              my_extremile_upp_t2max = my_extremile_upp_t2max,
              my_extremile_low_t2min = my_extremile_low_t2min,
              my_ES_upp_t2m = my_ES_upp_t2m,
              my_ES_low_t2m = my_ES_low_t2m,
              my_ES_upp_t2max = my_ES_upp_t2max,
              my_ES_low_t2min = my_ES_low_t2min
  )
  )
}
```

We provide the code used to apply the `compute_normal` function in parallel across all grid cells, enabling efficient computation of threshold values over the entire spatial domain.

NOTE that the cell directory is not included on Github
```{r}
# use of // computing 
my_dir <- "/Users/thibaultlaurent/Documents/ANR_flows/climate_variable/cell/cell"  # "/Volumes/NO NAME/cell"
my_file <- dir(my_dir)
nb_file <- substr(my_file, 6, nchar(my_file) - 4)
# nb_file <- 1:N
```

```{r, message = F, eval = F}
require(parallel)
P <- 10
cl <- makeCluster(P)
clusterExport(cl, c("unique_nom_file", "my_dir", "extremile_L", "ES"))
system.time(
  my_res <- clusterApply(cl, split(nb_file, rep(1:10, length.out = length(nb_file))), 
                         fun = compute_normal) # splitIndices(N, P)
)
stopCluster(cl)

temp_normal_t2min_low <- list(Q = my_res[[1]][[4]], 
                              E = my_res[[1]][[8]] , 
                              ES = my_res[[1]][[12]])
temp_normal_t2max_upp <- list(Q = my_res[[1]][[3]], 
                              E = my_res[[1]][[7]], 
                              ES = my_res[[1]][[11]])
temp_normal_t2m_low <- list(Q = my_res[[1]][[2]], 
                            E = my_res[[1]][[6]], 
                            ES = my_res[[1]][[10]])
temp_normal_t2m_upp <- list(Q = my_res[[1]][[1]], 
                            E = my_res[[1]][[5]], 
                            ES = my_res[[1]][[9]] )


for(k in 2:P) {
  temp_normal_t2m_upp$Q <- rbind(temp_normal_t2m_upp$Q, my_res[[k]][[1]])
  temp_normal_t2m_low$Q <- rbind(temp_normal_t2m_low$Q, my_res[[k]][[2]])
  temp_normal_t2max_upp$Q <- rbind(temp_normal_t2max_upp$Q, my_res[[k]][[3]])
  temp_normal_t2min_low$Q <- rbind(temp_normal_t2min_low$Q, my_res[[k]][[4]])
  temp_normal_t2m_upp$E <- rbind(temp_normal_t2m_upp$E, my_res[[k]][[5]])
  temp_normal_t2m_low$E <- rbind(temp_normal_t2m_low$E, my_res[[k]][[6]])
  temp_normal_t2max_upp$E <- rbind(temp_normal_t2max_upp$E, my_res[[k]][[7]]) 
  temp_normal_t2min_low$E <- rbind(temp_normal_t2min_low$E, my_res[[k]][[8]]) 
  temp_normal_t2m_upp$ES <- rbind(temp_normal_t2m_upp$ES, my_res[[k]][[9]]) 
  temp_normal_t2m_low$ES <- rbind(temp_normal_t2m_low$ES, my_res[[k]][[10]]) 
  temp_normal_t2max_upp$ES <- rbind(temp_normal_t2max_upp$ES, my_res[[k]][[11]]) 
  temp_normal_t2min_low$ES <- rbind(temp_normal_t2min_low$ES, my_res[[k]][[12]]) 
}

save(temp_normal_t2m_upp, temp_normal_t2m_low, 
     temp_normal_t2max_upp, temp_normal_t2min_low,
     file = "results/climate_normal.RData")  

# what we need to lunch // computing 
save("unique_nom_file", "all_files", "list_var", "my_dir",
     "all_days", "nT", "unique_year", "before_2011", "days_per_year",
     "temp_normal_t2max_upp", "temp_normal_t2min_low",
     "temp_normal_t2m_upp", "temp_normal_t2m_low",
     file = "results/to_parallel.RData")
```

```{r, eval = F, echo = F}
load("results/climate_normal.RData")
```

### Illustration

We provide the codes used to obtain the figure titled *Daily temperature values used to construct local climate normals over the month of August for the Geneva grid cell. Panels display maximum (left), minimum (middle), and mean (right) temperatures. Each plot includes three types of threshold curves estimated over the 1981–2010 reference period: $10$th and $90$th percentiles (red), extremiles of order $0.1$ and $0.9$ (blue), and expected shortfalls at the $10\%$ and $90\%$ levels (green).* 

```{r, fig.width = 12, fig.height = 4.5}
cols <- RColorBrewer::brewer.pal(3, "Set1")
coords_cell <- c(LON = 6.25, LAT = 46) # Geneva
nom_cell <- "Geneva"

ind_cell <- unique_nom_file[unique_nom_file[, "long"] == coords_cell["LON"] & 
                           unique_nom_file[, "lat"] == coords_cell["LAT"], "cell"]

cell_example <- read.table(paste0("data/cell_", ind_cell, ".csv"),
                        header = F, sep = ";", 
                        colClasses = c("character", "numeric", "numeric",
                                       "numeric", "numeric"),
                        col.names = c("YYYYMMDD", "T2MMEAN", "T2MMIN", "T2MMAX",
                                      "PRECTOTCORR"))
vec_theshold <- c(0.1, 0.01)
for(threshold in c(1, 2)) {
# pdf(paste0("figures/normal_temp_", threshold, ".pdf"), 
#     width = 9, height = 3.4)
par(las = 1, oma = c(0, 0, 0, 0), mar = c(4, 3.5, 0.5, 0.5), 
    mgp = c(2.5, 1, 0), mfrow = c(1, 3))
# layout(matrix(c(1, 3, 2, 3), ncol = 2, byrow = TRUE), 
# heights = c(0.5, 0.5))

#########################
########.  T2MMIN et T2MMAX 

normal_example_min <- normal_example_max <- vector("list", 31)
temp_filter <- cell_example[as.numeric(substr(cell_example$YYYYMMDD, 1, 4)) <= 2010, ] 
data_july <- c(paste0("07-", 25:31), paste0("08-0", 1:9), 
               paste0("08-", 11:31), paste0("09-0", 1:8))
for(k in 1:31) {
  temp_filter_k <- temp_filter[substr(temp_filter$YYYYMMDD, 6, 10) %in% data_july[k + (0:14)], ] 
  normal_example_min[[k]] <- temp_filter_k$T2MMIN
  normal_example_max[[k]] <- temp_filter_k$T2MMAX
}

quantile_90 <- extremile_90 <- es_90 <- numeric(31)
quantile_10 <- extremile_10 <- es_10 <- numeric(31)

plot(rep(1, length(normal_example_max[[1]])) + rnorm(length(normal_example_max[[1]]),
                                              sd =  0.03), 
     normal_example_max[[1]], 
     xlim = c(1, 31), xaxt = "n", 
     ylim = range(unlist(normal_example_min) - 2, unlist(normal_example_max) + 2),
     xlab = "Day of the year (Zoom on August)", 
     ylab = "Temperature (in degree C)", pch = 16, col = rgb(1, 0, 1, 0.5),
     cex = 0.2)

axis(1, at = 1:31, labels = FALSE)
text(x = 1:31, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = paste0("Aug ", 1:31), 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)
for(k in 2:31) {
  points(rep(k-0.1, length(normal_example_max[[k]])) +
           rnorm(length(normal_example_max[[k]]),            
                 sd =  0.03), 
     normal_example_max[[k]], 
     pch = 16, col = rgb(1, 0, 1, 0.5),
     cex = 0.2)  
}
for(k in 1:31) {
  quantile_90[k] <- quantile(normal_example_max[[k]], 
                             1 - vec_theshold[threshold])
  extremile_90[k] <- extremile_L(normal_example_max[[k]], 
                                 1 - vec_theshold[threshold])
  es_90[k] <- ES(normal_example_max[[k]], 1 - vec_theshold[threshold])
}
  
  lines(1:31, quantile_90, col = cols[1], lty = 2, lwd = 1.4)
  lines(1:31, extremile_90, col = cols[2], lty = 1, lwd = 1.4)
  lines(1:31, es_90, col = cols[3], lty = 4, lwd = 1.4)
  cat("Tmax: \n")
  cat("E:", max(extremile_90 - quantile_90), 
      "\n  ES", max(es_90 - quantile_90), "\n \n")
  
  legend("bottomright", 
    legend = c(TeX(sprintf(r'($T^{MAX}_{%s,d',t}$ for $d' \in W_d$,  $t \in [1981;2010]$)', 
                           nom_cell)),
               TeX(sprintf(r'($Q_{%s,d}^{0.9,MAX}$)', nom_cell)),
               TeX(sprintf(r'($E_{%s,d}^{0.9,MAX}$)', nom_cell)),
               TeX(sprintf(r'($ES_{%s,d}^{0.9,MAX}$)', nom_cell))),
       lty = c(NA, 2, 1, 4), col = c("magenta", cols),
       lwd = c(NA, 1, 1, 1), pch = c(16, NA, NA, NA), cex = 0.9)
  
  #######
  ## T2MIN
  
  plot(rep(1, length(normal_example_min[[1]])) + rnorm(length(normal_example_min[[1]]),
                                              sd =  0.03), 
     normal_example_min[[1]], 
     xlim = c(1, 31), xaxt = "n", 
     ylim = range(unlist(normal_example_min) - 2, unlist(normal_example_max) + 2),
     xlab = "Day of the year (Zoom on August)", 
     ylab = "Temperature (in degree C)", pch = 16, col = rgb(0, 1, 1, 0.5),
     cex = 0.2)

axis(1, at = 1:31, labels = FALSE)
text(x = 1:31, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = paste0("Aug ", 1:31), 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)
for(k in 2:31) {
 points(rep(k+0.1, length(normal_example_min[[k]])) +
          rnorm(length(normal_example_min[[k]]), 
                sd =  0.03), 
     normal_example_min[[k]], 
     pch = 16, col = rgb(0, 1, 1, 0.5),
     cex = 0.2) 
}
for(k in 1:31) {
  quantile_10[k] <- quantile(normal_example_min[[k]],
                             vec_theshold[threshold])
  extremile_10[k] <- extremile_L(normal_example_min[[k]], 
                              vec_theshold[threshold])
  es_10[k] <- ES(normal_example_min[[k]], vec_theshold[threshold])
}

  lines(1:31, quantile_10, col = cols[1], lty = 2, lwd = 1.4)
  lines(1:31, extremile_10, col = cols[2], lty = 1, lwd = 1.4)
  lines(1:31, es_10, col = cols[3], lty = 4, lwd = 1.4)
  
  cat("Tmin: \n")
  cat("E:", max(quantile_10 - extremile_10), 
      "\n  ES", max(quantile_10 - es_10), "\n \n")
  
  legend("topright", 
    legend = c(TeX(sprintf(r'($T^{MIN}_{%s,d',t}$ for $d' \in W_d$,  $t \in [1981;2010]$)', 
                           nom_cell)),
               TeX(sprintf(r'($Q_{%s,d}^{0.1,MIN}$)', nom_cell)),
               TeX(sprintf(r'($E_{%s,d}^{0.1,MIN}$)', nom_cell)),
               TeX(sprintf(r'($ES_{%s,d}^{0.1,MIN}$)', nom_cell))),
       lty = c(NA, 2, 1, 4), col = c("cyan", cols),
       lwd = c(NA, 1, 1, 1), pch = c(16, NA, NA, NA), cex = 0.9)
  
#########################
########.  T2MMEAN 

normal_example <- vector("list", 31)
temp_filter <- cell_example[as.numeric(substr(cell_example$YYYYMMDD, 1, 4)) <= 2010, ] 
data_july <- c(paste0("07-", 25:31), paste0("08-0", 1:9), 
               paste0("08-", 11:31), paste0("09-0", 1:8))
for(k in 1:31) {
  temp_filter_k <- temp_filter[substr(temp_filter$YYYYMMDD, 6, 10) %in% data_july[k + (0:14)], ] 
  normal_example[[k]] <- temp_filter_k$T2MMEAN
}


quantile_90 <- extremile_90 <- es_90 <- numeric(31)
quantile_10 <- extremile_10 <- es_10 <- numeric(31)

plot(rep(1, length(normal_example[[1]])) + rnorm(length(normal_example[[1]]),
                                              sd =  0.03), 
     normal_example[[1]], 
     xlim = c(1, 31), xaxt = "n", 
     ylim = range(unlist(normal_example_min) - 2, unlist(normal_example_max) + 2),
     xlab = "Day of the year (Zoom on August)", 
     ylab = "Temperature (in degree C)", pch = 16, col = rgb(0.5, 0.5, 0.5, 0.5),
     cex = 0.5)
axis(1, at = 1:31, labels = FALSE)
text(x = 1:31, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = paste0("Aug ", 1:31), 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)
for(k in 2:31)
 points(rep(k, length(normal_example[[k]])) + rnorm(length(normal_example[[k]]), sd =  0.03), 
     normal_example[[k]], 
     pch = 16, col = rgb(0.5, 0.5, 0.5, 0.5),
     cex = 0.5) 

for(k in 1:31) {
  
  quantile_90[k] <- quantile(normal_example[[k]], 
                             1 - vec_theshold[threshold])
  quantile_10[k] <- quantile(normal_example[[k]], 
                             vec_theshold[threshold])
  
  extremile_90[k] <- extremile_L(normal_example[[k]], 
                                 1 - vec_theshold[threshold])
  extremile_10[k] <- extremile_L(normal_example[[k]], 
                                 vec_theshold[threshold])
  
  es_90[k] <- ES(normal_example[[k]], 1 - vec_theshold[threshold])
  es_10[k] <- ES(normal_example[[k]], vec_theshold[threshold])
  
}

  lines(1:31, quantile_90, col = cols[1], lty = 2, lwd = 1.4)
  lines(1:31, extremile_90, col = cols[2], lty = 1, lwd = 1.4)
  lines(1:31, es_90, col = cols[3], lty = 4, lwd = 1.4)
  
  lines(1:31, quantile_10, col = cols[1], lty = 2, lwd = 1.4)
  lines(1:31, extremile_10, col = cols[2], lty = 1, lwd = 1.4)
  lines(1:31, es_10, col = cols[3], lty = 4, lwd = 1.4)
  
  
  cat("T2M: \n")
  cat("E:", max(extremile_90 - quantile_90), 
      "\n  ES", max(es_90 - quantile_90), "\n")
  cat("E:", max(quantile_10 - extremile_10), 
      "\n  ES", max(quantile_10 - es_10), "\n \n")
    
  legend("topright", 
    legend = c(TeX(sprintf(r'($T^{MEAN}_{%s,d',t}$ for $d' \in W_d$,  $t \in [1981;2010]$)', 
                           nom_cell)),
               TeX(sprintf(r'($Q_{%s,d}^{0.1,MEAN}$ and $Q_{%s,d}^{0.9,MEAN}$)', 
                           nom_cell, nom_cell)),
               TeX(sprintf(r'($E_{%s,d}^{0.1,MEAN}$ and $E_{%s,d}^{0.9,MEAN}$)', 
                           nom_cell, nom_cell)),
               TeX(sprintf(r'($ES_{%s,d}^{0.1,MEAN}$ and $ES_{%s,d}^{0.9,MEAN}$)', 
                           nom_cell, nom_cell))),
       lty = c(NA, 2, 1, 4), col = c("grey", cols),
       lwd = c(NA, 1, 1, 1), pch = c(16, NA, NA, NA), cex = 0.9)
#dev.off()
}
```



## Heat and cold event indicators based on local extremes



We provide the code used to generate the figure titled *Daily temperature series for 2003 in Geneva, overlaid with three types of thresholds based on the 1981–2010 reference period: 90th percentiles (left), upper extremiles (middle), and expected shortfalls (right). The top row shows daily minimum and maximum temperatures; the bottom row shows daily mean temperatures. Dashed lines indicate smoothed threshold values. Red (or blue) shaded areas highlight periods where temperatures stay above (or below) the threshold long enough to qualify as warm or cold events.*

```{r, fig.width = 20, fig.height = 10}
# \caption{Observed daily temperatures in Geneva in 2003, overlaid with thresholds based on quantiles (left), extremiles (center), and expected shortfall (right). Top: daily minimum and maximum temperatures; bottom: daily mean temperature. Shaded areas indicate warm or cold spells and heatwave/cold wave events.}
nom_cell_label <- "Gv"
obs_year <- 2003
obs_year_st <- "3"
type_normal = "Q"

temp_observed_t2min <- cell_example[substr(cell_example$YYYYMMDD, 1, 4) == obs_year,
                                    "T2MMIN"] 
temp_observed_t2max <- cell_example[substr(cell_example$YYYYMMDD, 1, 4) == obs_year,
                                    "T2MMAX"] 
temp_observed_t2m <- cell_example[substr(cell_example$YYYYMMDD, 1, 4) == obs_year,
                                  "T2MMEAN"]
date_year <- 1:length(temp_observed_t2m)

temp_normal_cell <- compute_normal(ind_cell)

temp_normal_plot <- lapply(temp_normal_cell, function(x) unlist(x[, -c(1, 2)]))
if(length(date_year) == 365) {
  temp_normal_plot <- lapply(temp_normal_plot, function(x) unlist(x)[-60])
}  

temp_normal_t2min_low <- list(Q = temp_normal_plot[[4]], 
                              E = temp_normal_plot[[8]], 
                              ES = temp_normal_plot[[12]] )
temp_normal_t2max_upp <- list(Q = temp_normal_plot[[3]], 
                              E = temp_normal_plot[[7]], 
                              ES = temp_normal_plot[[11]])
temp_normal_t2m_low <- list(Q = temp_normal_plot[[2]], 
                            E = temp_normal_plot[[6]], 
                            ES = temp_normal_plot[[10]])
temp_normal_t2m_upp <- list(Q = temp_normal_plot[[1]], 
                            E = temp_normal_plot[[5]], 
                            ES = temp_normal_plot[[9]])

#pdf(file = "figures/indicator.pdf", width = 20 * 0.6, height = 10*0.6)
par(las = 1, mfcol = c(2, 3), oma = c(0, 0, 0, 0),
    mar = c(3, 3.5, 1, 1), mgp = c(2.5, 1, 0))
for(type_normal in c("Q", "E", "ES")) {
##################################################
plot(date_year, temp_normal_t2min_low[[type_normal]], type = "l", xlab = "", 
     ylim = range(c(temp_normal_t2min_low[[type_normal]], temp_observed_t2min, 
                    temp_normal_t2max_upp[[type_normal]]+1.5, temp_observed_t2max+1.5)),
     col = cols[1], lty = 2, xaxt = "n", 
     ylab = "Temperatures (in degree C)")

axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)

lines(date_year, temp_normal_t2max_upp[[type_normal]], 
      col = cols[1], lty = 2)
lines(date_year, temp_observed_t2min, col = rgb(0, 1, 1, alpha = 0.6))
lines(date_year, temp_observed_t2max, col = rgb(1, 0, 1, alpha = 0.6))

ind_low <- which(temp_observed_t2min < temp_normal_t2min_low[[type_normal]])
ind_upp <- which(temp_observed_t2max > temp_normal_t2max_upp[[type_normal]])

# legend
legend("topleft", legend = c(TeX(sprintf(r'($T_{%s,d,%s}^{0.9,MAX}$)', nom_cell_label,
                                         obs_year_st)),
                             TeX(sprintf(r'($%s_{%s,d}^{0.9,MAX}$)', type_normal,
                                         nom_cell_label)),
                             TeX(sprintf(r'($WSDI_{%s,%s}^{%s}$)', 
                                         nom_cell_label, obs_year_st, type_normal)),
                             TeX(sprintf(r'($T_{%s,d,%s}^{0.1,MIN}$)', nom_cell_label,
                                         obs_year_st)), 
                             TeX(sprintf(r'($%s_{%s,d}^{0.1,MIN}$)', type_normal,
                                         nom_cell_label)), 
                             TeX(sprintf(r'($CSDI_{%s,%s}^{%s}$)', 
                                         nom_cell_label, obs_year_st, type_normal))),
       lty = c(1, 2, 1, 1, 2, 1), col = c(rgb(1, 0, 1, alpha = 0.6), cols[1], "red",
                                          rgb(0, 1, 1, alpha = 0.6), cols[1], "blue"),
       lwd = c(1, 1, 2, 1, 1, 2),
       cex = 0.95)
# print the values up to the upper bound
ind_to_print <- vector("list", 0)
nb_suit <- 1
temp <- 1
for(k in 2:length(ind_upp)) {
  if(ind_upp[k] - ind_upp[k-1] == 1) {
    temp <- temp + 1
  } else {
    if (temp >= 6) {
      ind_to_print[[nb_suit]] <- ind_upp[(k-temp):(k-1)]
      temp <- 1
      lines(date_year[ind_to_print[[nb_suit]]], temp_observed_t2max[ind_to_print[[nb_suit]]], 
            lwd = 2, col = "red")
      if (nb_suit == 1) {
        arrows(date_year[min(ind_to_print[[nb_suit]])] - 0.1, min(temp_normal_t2max_upp[[type_normal]][ind_to_print[[nb_suit]]]), 
               date_year[min(ind_to_print[[nb_suit]])] - 0.1, max(temp_observed_t2max[ind_to_print[[nb_suit]]]), lwd = 1,
               length = 0.05, code = 3)
        text(date_year[min(ind_to_print[[nb_suit]])],  mean(temp_observed_t2max[ind_to_print[[nb_suit]]]),
             TeX(sprintf(r'($WSEI_{%s,%s}^{%s}$)',
                         nom_cell_label, obs_year_st, type_normal)), pos = 2)
      }
      nb_suit <- nb_suit + 1
    }
    temp <- 1
  }
}
ind_max <- which.max(sapply(ind_to_print, length))
if(length(ind_max) > 0) {
  arrows(date_year[min(ind_to_print[[ind_max]])], max(temp_observed_t2max[ind_to_print[[ind_max]]]) + 0.3, 
         date_year[max(ind_to_print[[ind_max]])], max(temp_observed_t2max[ind_to_print[[ind_max]]]) + 0.3, lwd = 1,
         length = 0.05, code = 3)
  text(date_year[max(ind_to_print[[ind_max]])],  max(temp_observed_t2max[ind_to_print[[ind_max]]]) + 0.3,
       TeX(sprintf(r'($WSD_{%s,%s}^{%s}$)', 
                   nom_cell_label, obs_year_st, type_normal)), pos = 4)
}

# print the values up to the LOWER bound
ind_to_print <- vector("list", 0)
nb_suit <- 1
temp <- 1
for(k in 2:length(ind_low)) {
  if(ind_low[k] - ind_low[k-1] == 1) {
    temp <- temp + 1
  } else {
    if (temp >= 6) {
      ind_to_print[[nb_suit]] <- ind_low[(k-temp):(k-1)]
      temp <- 1
      lines(date_year[ind_to_print[[nb_suit]]], temp_observed_t2min[ind_to_print[[nb_suit]]], 
            lwd = 2, col = "blue")
      if (nb_suit == 1) {
        arrows(date_year[min(ind_to_print[[nb_suit]])] - 0.1, min(temp_normal_t2min_low[[type_normal]][ind_to_print[[nb_suit]]]), 
               date_year[min(ind_to_print[[nb_suit]])] - 0.1, max(temp_observed_t2min[ind_to_print[[nb_suit]]]), 
               lwd = 1,
               length = 0.05, code = 3)
        text(date_year[min(ind_to_print[[nb_suit]])],  mean(temp_observed_t2min[ind_to_print[[nb_suit]]]),
             TeX(sprintf(r'($CSEI_{%s,%s}^{%s}$)', 
                         nom_cell_label, obs_year_st, type_normal)), pos = 2)
      }
      nb_suit <- nb_suit + 1
    }
    temp <- 1
  }
}
ind_max <- which.max(sapply(ind_to_print, length))
if(length(ind_max) > 0) {
  arrows(date_year[min(ind_to_print[[ind_max]])], min(temp_observed_t2min[ind_to_print[[ind_max]]]) - 0.3, 
         date_year[max(ind_to_print[[ind_max]])], min(temp_observed_t2min[ind_to_print[[ind_max]]]) - 0.3, lwd = 1,
         length = 0.05, code = 3)
  text(date_year[max(ind_to_print[[ind_max]])],  min(temp_observed_t2min[ind_to_print[[ind_max]]]) - 0.3,
       TeX(sprintf(r'($CSD_{%s,%s}^{%s}$)',
                   nom_cell_label, obs_year_st, type_normal)), pos = 4)
}

###############
##################################################
plot(date_year, temp_normal_t2m_low[[type_normal]], type = "l", xlab = "", 
      ylab = "Temperatures (in degree C)",
     ylim = range(c(temp_normal_t2m_low[[type_normal]], 
                    temp_observed_t2m, 
                    temp_normal_t2m_upp[[type_normal]])),
     lty = 2, col = "blue", xaxt = "n")

axis(1, at = deb_month, labels = FALSE)
text(x = deb_month, y = par()$usr[3] - 0.03 * (par()$usr[4] - par()$usr[3]),
     labels = month.name, 
     srt = 45, adj = 1, xpd = TRUE, cex = 0.8)

lines(date_year, temp_normal_t2m_upp[[type_normal]], lty = 2, col = "red")
lines(date_year, temp_observed_t2m, col = rgb(0, 0, 0, alpha = 0.3))

# legend
legend("topleft", legend = c(TeX(sprintf(r'($T_{%s,d,%s}^{MEAN}$)', nom_cell_label, obs_year_st)),
                             TeX(sprintf(r'($%s_{%s,d}^{0.9,MEAN}$)', type_normal,
                                         nom_cell_label)),
                             TeX(sprintf(r'($HWF_{%s,%s}^{%s}$)',
                                         nom_cell_label, obs_year_st, type_normal)),
                             TeX(sprintf(r'($%s_{%s,d}^{0.1,MEAN}$)', type_normal,
                                         nom_cell_label)), 
                             TeX(sprintf(r'($CWF_{%s,%s}^{%s}$)',
                                         nom_cell_label, obs_year_st, type_normal))),
       lty = c(1, 2, 1, 2, 1), 
       col = c(rgb(0, 0, 1, alpha = 0.3), "red", "red", "blue", "blue"),
       lwd = c(1, 1, 2, 1, 2),
       cex = 0.95)

ind_low <- which(temp_observed_t2m < temp_normal_t2m_low[[type_normal]])
ind_upp <- which((temp_observed_t2m > temp_normal_t2m_upp[[type_normal]]) &
                   (temp_observed_t2max > 28))

# print the values up to the upper bound
ind_to_print <- vector("list", 0)
nb_suit <- 1
temp <- 1
for(k in 2:length(ind_upp)) {
  if(ind_upp[k] - ind_upp[k-1] == 1) {
    temp <- temp + 1
  } else {
    if (temp >= 3) {
      ind_to_print[[nb_suit]] <- ind_upp[(k-temp):(k-1)]
      temp <- 1
      lines(date_year[ind_to_print[[nb_suit]]], temp_observed_t2m[ind_to_print[[nb_suit]]], 
            lwd = 2, col = "red")
      if (nb_suit == 1) {
        arrows(date_year[min(ind_to_print[[nb_suit]])] - 0.1, min(temp_normal_t2m_upp[[type_normal]][ind_to_print[[nb_suit]]]), 
               date_year[min(ind_to_print[[nb_suit]])] - 0.1, max(temp_observed_t2m[ind_to_print[[nb_suit]]]), lwd = 1,
               length = 0.05, code = 3)
        text(date_year[min(ind_to_print[[nb_suit]])],  mean(temp_observed_t2m[ind_to_print[[nb_suit]]]),
             TeX(sprintf(r'($HWEI_{%s,%s}^{%s}$)',
                         nom_cell_label, obs_year_st, type_normal)), pos = 2)
      }
      nb_suit <- nb_suit + 1
    }
    temp <- 1
  }
}
ind_max <- which.max(sapply(ind_to_print, length))

if(length(ind_max) > 0) {
  arrows(date_year[min(ind_to_print[[ind_max]])], max(temp_observed_t2m[ind_to_print[[ind_max]]]) + 0.3, 
         date_year[max(ind_to_print[[ind_max]])], max(temp_observed_t2m[ind_to_print[[ind_max]]]) + 0.3, lwd = 1,
         length = 0.05, code = 3)
  text(date_year[max(ind_to_print[[ind_max]])],  max(temp_observed_t2m[ind_to_print[[ind_max]]]) - 0.4,
       TeX(sprintf(r'($HWD_{%s,%d}^{%s}$)',
                   nom_cell_label, obs_year, type_normal)), pos = 4)
}

# print the values up to the upper bound
ind_to_print <- vector("list", 0)
nb_suit <- 1
temp <- 1
if(length(ind_low) > 0) {
for(k in 2:length(ind_low)) {
  if(ind_low[k] - ind_low[k-1] == 1) {
    temp <- temp + 1
  } else {
    if (temp >= 3) {
      ind_to_print[[nb_suit]] <- ind_low[(k-temp):(k-1)]
      temp <- 1
      lines(date_year[ind_to_print[[nb_suit]]], temp_observed_t2m[ind_to_print[[nb_suit]]], 
            lwd = 2, col = "blue")
      if (nb_suit == 1) {
        arrows(date_year[min(ind_to_print[[nb_suit]])] - 0.1, min(temp_normal_t2m_low[[type_normal]][ind_to_print[[nb_suit]]]), 
               date_year[min(ind_to_print[[nb_suit]])] - 0.1, max(temp_observed_t2m[ind_to_print[[nb_suit]]]), lwd = 1,
               length = 0.05, code = 3)
        text(date_year[min(ind_to_print[[nb_suit]])] + 8,  mean(temp_observed_t2m[ind_to_print[[nb_suit]]]),
             TeX(sprintf(r'($CWEI_{%s,%s}^{%s}$)',
                         nom_cell_label, obs_year_st, type_normal)), pos = 1)
      }
      nb_suit <- nb_suit + 1
    }
    temp <- 1
  }
}
}
ind_max <- which.max(sapply(ind_to_print, length))

if(length(ind_max) > 0) {
  arrows(date_year[min(ind_to_print[[ind_max]])], min(temp_observed_t2m[ind_to_print[[ind_max]]]) - 0.3, 
         date_year[max(ind_to_print[[ind_max]])], min(temp_observed_t2m[ind_to_print[[ind_max]]]) - 0.3, lwd = 1,
         length = 0.05, code = 3)
  text(date_year[max(ind_to_print[[ind_max]])],  min(temp_observed_t2m[ind_to_print[[ind_max]]]) - 0.3,
       TeX(sprintf(r'($CWD_{%s,%s}^{%s}$)',
                   nom_cell_label, obs_year_st, type_normal)), pos = 4)
}
}
#dev.off()
```

The `compute_stat` function computes the full set of climate indicators developed in this work for a given set of grid cells.

```{r, message = F, warning = F}
#########################
# function to be parallelized
compute_stat <- function(vec_z) {
  
  # initialisation
  res_final <- data.frame(
    long = unique_nom_file$long[as.numeric(vec_z)],
    lat =  unique_nom_file$lat[as.numeric(vec_z)])
  
  row.names(res_final) <- vec_z
  res_final[, paste0(list_var, "_", rep(unique_year, each = length(list_var)))] <- 0 
  
  for(z in 1:length(vec_z)) {
    file_import <- read.table(paste0(my_dir, "/cell_", vec_z[z], ".csv"),
                              header = F, sep = ";", 
                              colClasses = c("character", "numeric", "numeric",
                                             "numeric", "numeric"),
                              col.names = c("YYYYMMDD", "T2MMEAN", "T2MMIN", "T2MMAX", "PRECTOTCORR"))
    
    # normal temperatures
    t2m_normal <- mean(file_import$T2MMEAN[before_2011])
    t2min_normal <- mean(file_import$T2MMIN[before_2011])
    t2max_normal <- mean(file_import$T2MMAX[before_2011])
    prec_normal <- mean(file_import$PRECTOTCORR[before_2011])
    
    temp_normal <- aggregate(file_import[, c("T2MMEAN", "T2MMAX", "T2MMIN", "PRECTOTCORR")], 
                             by = list(year = substr(file_import$YYYYMMDD, 1, 4)),
                             mean)
    
    res_final[z, paste0("t2m_diff_", unique_year)] <- temp_normal$T2MMEAN - t2m_normal
    res_final[z, paste0("t2min_diff_", unique_year)] <- temp_normal$T2MMIN - t2min_normal 
    res_final[z, paste0("t2max_diff_", unique_year)] <- temp_normal$T2MMAX - t2max_normal 
    res_final[z, paste0("prec_diff_", unique_year)] <- (temp_normal$PRECTOTCORR - prec_normal) *
      days_per_year
    
    #### Dry and wet criteria 
    # https://www.sciencedirect.com/science/article/pii/S0169809520310747
    
    consecutive_days_dry <- file_import %>% 
      group_by(grp = cumsum(PRECTOTCORR > 1), year = substr(YYYYMMDD, 1, 4)) %>%
      filter(PRECTOTCORR <= 1) %>% 
      summarise(start_date = min(YYYYMMDD),
                end_date = max(YYYYMMDD),
                days_con = n()) %>% 
      dplyr::select(-grp) %>%
      group_by(year) %>%
      summarise(my_max = max(days_con)) 
    
    if(length(consecutive_days_dry$year) != 0) {
      res_final[z, paste0("dry_", consecutive_days_dry$year)] <- consecutive_days_dry$my_max
    }
    # wet
    consecutive_days_wet <- file_import %>% 
      group_by(grp = cumsum(PRECTOTCORR <= 1), year = substr(YYYYMMDD, 1, 4)) %>%
      filter(PRECTOTCORR > 1) %>% 
      summarise(start_date = min(YYYYMMDD),
                end_date = max(YYYYMMDD),
                days_con = n()) %>% 
      dplyr::select(-grp) %>%
      group_by(year) %>%
      summarise(my_max = max(days_con)) 
    
    if(length(consecutive_days_wet$year) != 0) {
      res_final[z, paste0("wet_", consecutive_days_wet$year)] <- consecutive_days_wet$my_max
    }
    
    # 5-days-precipitation and maximum observed during the precipitations 
    sum_5days <- file_import$PRECTOTCORR +
      c(0, file_import$PRECTOTCORR)[-c(nT)] +
      c(0, 0, file_import$PRECTOTCORR)[-c((nT-1):nT)] +
      c(0, 0, 0, file_import$PRECTOTCORR)[-c((nT-2):nT)] +
      c(0, 0, 0, 0, file_import$PRECTOTCORR)[-c((nT-3):nT)] 
    
    res_final[z, paste0("prec_5days_", unique_year)] <- 
      aggregate(sum_5days, by = list(year = substr(all_days, 1, 4)), max)$x
    
    #res_final[z, paste0("t2max_5days_", unique_year)] <- 
    #  sapply(aggregate(sum_5days, by = list(year = substr(all_days, 1, 4)), which.max)$x + 
    #           c(0, cumsum(days_per_year[-length(days_per_year)])), function(x)
    #             max(file_import$T2MMAX[(x-4):x]))
    
    #  5-day heatwave events with daily maximum temperature greater than 35°C
    # Ref : https://www.nature.com/articles/sdata2018206
    consecutive_days_above35 <- file_import %>% 
      group_by(grp = cumsum(T2MMAX <= 35), year = substr(YYYYMMDD, 1, 4)) %>%
      filter(T2MMAX > 35) %>% 
      summarise(start_date = min(YYYYMMDD),
                end_date = max(YYYYMMDD),
                days_con = n()) %>% 
      dplyr::select(-grp) %>%
      filter(days_con >= 5) %>%
      group_by(year) %>%
      summarise(ghwr_35 = sum(days_con)) 
    
    if(length(consecutive_days_above35$year) != 0) {
      res_final[z, paste0("ghwr_35_", consecutive_days_above35$year)] <- consecutive_days_above35$ghwr_35
    }
    
    ####################
    # warm spell
    for(type_ex in c("Q", "E", "ES")) {
      normal_vec_max_warm_spell <- as.numeric(temp_normal_t2max_upp[[type_ex]][as.character(vec_z[z]), -c(1, 2)])
      normal_vec_min_warm_spell <- as.numeric(temp_normal_t2min_low[[type_ex]][as.character(vec_z[z]), -c(1, 2)])
      normal_vec_max_heat_wave <- as.numeric(temp_normal_t2m_upp[[type_ex]][as.character(vec_z[z]), -c(1, 2)])
      normal_vec_min_heat_wave <- as.numeric(temp_normal_t2m_low[[type_ex]][as.character(vec_z[z]), -c(1, 2)])
    
      file_import$max_warm_spell <-  rep(c(
        normal_vec_max_warm_spell[-60], normal_vec_max_warm_spell[-60],
        normal_vec_max_warm_spell[-60], normal_vec_max_warm_spell), times = 11)[1:nT]
    
      file_import$min_warm_spell = rep(c(
        normal_vec_min_warm_spell[-60], normal_vec_min_warm_spell[-60],
        normal_vec_min_warm_spell[-60], normal_vec_min_warm_spell), times = 11)[1:nT]
    
      file_import$max_heat_wave = rep(c(
        normal_vec_max_heat_wave[-60], normal_vec_max_heat_wave[-60],
        normal_vec_max_heat_wave[-60], normal_vec_max_heat_wave), times = 11)[1:nT]
    
      file_import$min_heat_wave = rep(c(
        normal_vec_min_heat_wave[-60], normal_vec_min_heat_wave[-60],
        normal_vec_min_heat_wave[-60], normal_vec_min_heat_wave), times = 11)[1:nT]
    
      consecutive_days_wsdi <- file_import %>% 
        group_by(grp = cumsum(T2MMAX <= max_warm_spell), 
               year = substr(YYYYMMDD, 1, 4)) %>%
        filter(T2MMAX > max_warm_spell & T2MMIN >= min_warm_spell) %>% 
        summarise(start_date = min(YYYYMMDD),
                end_date = max(YYYYMMDD),
                excess = sum(T2MMAX - max_warm_spell),
                days_con = n()) %>% 
        dplyr::select(-grp) %>%
        filter(days_con >= 6) %>%
        group_by(year) %>%
        summarise(wsdi = sum(days_con),
                wsd = max(days_con),
                wsei = sum(excess)/wsdi) 
    
      if(length(consecutive_days_wsdi$year) != 0) {
        res_final[z, paste0(type_ex, "_wsdi_upp_", consecutive_days_wsdi$year)] <- consecutive_days_wsdi$wsdi
        res_final[z, paste0(type_ex, "_wsd_upp_", consecutive_days_wsdi$year)] <- consecutive_days_wsdi$wsd
        res_final[z, paste0(type_ex, "_wsei_upp_", consecutive_days_wsdi$year)] <- consecutive_days_wsdi$wsei
      }
      
      # cold spell
      consecutive_days_csdi <- file_import %>% 
        group_by(grp = cumsum(T2MMIN > min_warm_spell), year = substr(YYYYMMDD, 1, 4)) %>%
        filter(T2MMIN <= min_warm_spell) %>% 
        summarise(start_date = min(YYYYMMDD),
                  end_date = max(YYYYMMDD),
                  excess = sum(T2MMIN - min_warm_spell),
                  days_con = n()) %>% 
        dplyr::select(-grp) %>%
        filter(days_con >= 6) %>%
        group_by(year) %>%
        summarise(csdi = sum(days_con),
                csd = max(days_con),
                csei = abs(sum(excess)/csdi)) 
    
      if(length(consecutive_days_csdi$year) != 0) {
        res_final[z, paste0(type_ex, "_wsdi_low_", consecutive_days_csdi$year)] <- consecutive_days_csdi$csdi
        res_final[z, paste0(type_ex, "_wsd_low_", consecutive_days_csdi$year)] <- consecutive_days_csdi$csd
        res_final[z, paste0(type_ex, "_wsei_low_", consecutive_days_csdi$year)] <- consecutive_days_csdi$csei
      }
      
      # heatwave
      # difference with warm spell according to UN : during summer 
      # https://www.undrr.org/understanding-disaster-risk/terminology/hips/mh0047 
      # definition in GB (MAX > 25 deg and threshol): https://rmets.onlinelibrary.wiley.com/doi/10.1002/wea.3629 
      consecutive_days_hwd <- file_import %>% 
        group_by(grp = cumsum(T2MMEAN <= max_heat_wave), 
                 year = substr(YYYYMMDD, 1, 4)) %>%
        filter(T2MMEAN > max_heat_wave & T2MMAX > 28) %>% 
        summarise(start_date = min(YYYYMMDD),
                  end_date = max(YYYYMMDD),
                  excess = sum(T2MMEAN - max_heat_wave),
                  days_con = n()) %>% 
        dplyr::select(-grp) %>%
        filter(days_con >= 3) %>%
        group_by(year) %>%
        summarise(hwf = sum(days_con),
                hwd = max(days_con),
                hwei = sum(excess)/hwf) 
    
      if(length(consecutive_days_hwd$year) != 0) {
        res_final[z, paste0(type_ex, "_hwf_upp_", consecutive_days_hwd$year)] <- consecutive_days_hwd$hwf
        res_final[z, paste0(type_ex, "_hwd_upp_", consecutive_days_hwd$year)] <- consecutive_days_hwd$hwd
        res_final[z, paste0(type_ex, "_hwei_upp_", consecutive_days_hwd$year)] <- consecutive_days_hwd$hwei
      }
      
      # Cold wave
      consecutive_days_cwd <- file_import %>% 
        group_by(grp = cumsum(T2MMEAN > min_heat_wave), year = substr(YYYYMMDD, 1, 4)) %>%
        filter(T2MMEAN <= min_heat_wave) %>% 
        summarise(start_date = min(YYYYMMDD),
                  end_date = max(YYYYMMDD),
                  excess = sum(T2MMEAN - min_heat_wave),
                  days_con = n()) %>% 
        dplyr::select(-grp) %>%
        filter(days_con >= 3) %>%
        group_by(year) %>%
        summarise(cwf = sum(days_con),
                cwd = max(days_con),
                cwei = sum(abs(excess))/cwf) 
    
      if(length(consecutive_days_cwd$year) != 0) {
        res_final[z, paste0(type_ex, "_hwf_low_", consecutive_days_cwd$year)] <- consecutive_days_cwd$cwf
        res_final[z, paste0(type_ex, "_hwd_low_", consecutive_days_cwd$year)] <- consecutive_days_cwd$cwd
        res_final[z, paste0(type_ex, "_hwei_low_", consecutive_days_cwd$year)] <- consecutive_days_cwd$cwei
      }
    }
  }
  return(res_final)
}

# example of use
unique_year <- 1981:2024
before_2011 <- which(all_days < "2011-01-01")
days_per_year <- as.numeric(table(substr(all_days, 1, 4)))
list_var <- c("t2m_diff", "t2min_diff", "t2max_diff", "ghwr_35",
              "prec_diff", "dry", "wet", "prec_5days",  
              paste0(rep(c("Q_", "E_", "ES_"), each = 12),
                     c("wsdi_upp",  "wsd_upp", "wsei_upp",  "hwf_upp", "hwd_upp", "hwei_upp",
                       "wsdi_low",  "wsd_low", "wsei_low",  "hwf_low", "hwd_low", "hwei_low")))  

title_var <- c("Difference from average T2M temp. (in degree C)", 
               "Difference from average T2MMIN temp. (in degree C)", 
               "Difference from average T2MMAX temp. (in degree C)", 
               "Total Number of Days Exceeding 35°C",
               "Difference from average precipitation (in mm)", 
               "Total Count of Dry Days", 
               "Total Count of Wet Days",
               "Maximum consecutive 5-days precipitation (in mm)",
               paste0(c("Annual count of days satisfying the warm spell risk",
                        "Length of the longest warm spell risk",
                        "Daily maximum temperature excess (upp) risk",
                        "Annual count of days satisfying the heat wave risk",
                        "Length of the longest heat wave risk",
                        "Daily mean temperature excess (upp) risk", 
                        "Annual count of days satisfying the cold spell risk",
                        "Length of the longest cold spell risk",
                        "Daily maximum temperature excess (low) risk",
                        "Annual count of days satisfying the warm wave risk",
                        "Length of the longest warm wave risk",
                        "Daily mean temperature excess (low) risk"),
                      rep(c(" (quantile)", " (extremile)", " (expected shortfall)"), 
                          each = 12))
)
temp_normal_t2min_low <- list(Q = temp_normal_cell[[4]], 
                              E = temp_normal_cell[[8]], 
                              ES = temp_normal_cell[[12]] )
temp_normal_t2max_upp <- list(Q = temp_normal_cell[[3]], 
                              E = temp_normal_cell[[7]], 
                              ES = temp_normal_cell[[11]])
temp_normal_t2m_low <- list(Q = temp_normal_cell[[2]], 
                            E = temp_normal_cell[[6]], 
                            ES = temp_normal_cell[[10]])
temp_normal_t2m_upp <- list(Q = temp_normal_cell[[1]], 
                            E = temp_normal_cell[[5]], 
                            ES = temp_normal_cell[[9]])
my_indicator <- compute_stat(ind_cell)
```

We generate the Table titled Comparison of climate indicators across threshold definitions (Quantile, Extremile, Expected Shortfall), which displays values computed for Geneva in 2003.


| **Indicator**                                  | **Quantile**                                                | **Extremile**                                               | **Expected Shortfall**                                      |
|------------------------------------------------|--------------------------------------------------------------|--------------------------------------------------------------|--------------------------------------------------------------|
| Warm Spell Duration Index (WSDI) [days]        | `r round(my_indicator[as.character(ind_cell), paste0("Q_wsdi_upp_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("E_wsdi_upp_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("ES_wsdi_upp_", obs_year)], 2)` |
| Warm Spell Duration (WSD) [days]               | `r round(my_indicator[as.character(ind_cell), paste0("Q_wsd_upp_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("E_wsd_upp_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("ES_wsd_upp_", obs_year)], 2)`  |
| Warm Spell Excess Index (WSEI) [°C]            | `r round(my_indicator[as.character(ind_cell), paste0("Q_wsei_upp_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("E_wsei_upp_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("ES_wsei_upp_", obs_year)], 2)` |
| Cold Spell Duration Index (CSDI) [days]        | `r round(my_indicator[as.character(ind_cell), paste0("Q_wsdi_low_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("E_wsdi_low_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("ES_wsdi_low_", obs_year)], 2)` |
| Cold Spell Duration (CSD) [days]               | `r round(my_indicator[as.character(ind_cell), paste0("Q_wsd_low_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("E_wsd_low_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("ES_wsd_low_", obs_year)], 2)`  |
| Cold Spell Excess Index (CSEI) [°C]            | `r round(my_indicator[as.character(ind_cell), paste0("Q_wsei_low_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("E_wsei_low_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("ES_wsei_low_", obs_year)], 2)` |
| Heatwave Duration (HWD) [days]                 | `r round(my_indicator[as.character(ind_cell), paste0("Q_hwd_upp_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("E_hwd_upp_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("ES_hwd_upp_", obs_year)], 2)`  |
| Heatwave Frequency (HWF) [days]                | `r round(my_indicator[as.character(ind_cell), paste0("Q_hwf_upp_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("E_hwf_upp_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("ES_hwf_upp_", obs_year)], 2)`  |
| Heatwave Excess Index (HWEI) [°C]              | `r round(my_indicator[as.character(ind_cell), paste0("Q_hwei_upp_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("E_hwei_upp_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("ES_hwei_upp_", obs_year)], 2)` |
| Cold Wave Duration (CWD) [days]                | `r round(my_indicator[as.character(ind_cell), paste0("Q_hwd_low_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("E_hwd_low_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("ES_hwd_low_", obs_year)], 2)`  |
| Cold Wave Frequency (CWF) [days]               | `r round(my_indicator[as.character(ind_cell), paste0("Q_hwf_low_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("E_hwf_low_", obs_year)], 2)`  | `r round(my_indicator[as.character(ind_cell), paste0("ES_hwf_low_", obs_year)], 2)`  |
| Cold Wave Excess Index (CWEI) [°C]             | `r round(my_indicator[as.character(ind_cell), paste0("Q_hwei_low_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("E_hwei_low_", obs_year)], 2)` | `r round(my_indicator[as.character(ind_cell), paste0("ES_hwei_low_", obs_year)], 2)` |


We provide the parallelized code used to compute the full set of climate indicators for each MERRA-2 grid cell.

```{r, eval = F, echo = F}
# codes for computing all indicators at cell s and year t
nb_core <- 4 
# list_z <- split(1:N, rep(1:nb_core, each = 51984)) 
list_z <- split(nb_file, rep(1:nb_core, length.out = length(nb_file)))
require(parallel)
cl <- makeCluster(nb_core)
clusterEvalQ(cl, {
  require(dplyr)
  load("results/to_parallel.RData")
})
system.time(
  res_stat_par <- clusterApply(cl, list_z, fun = compute_stat)
)
stopCluster(cl)
my_grid <- rbind(
  res_stat_par[[1]],
  res_stat_par[[2]],
  res_stat_par[[3]],
  res_stat_par[[4]])
save(my_grid, file = "results/my_grid_final.RData")
```


```{r, message = F, warning = F}
# transforn the points into grid
long_lat_temp <- my_grid[, c("long", "lat")] %>%
  filter(lat > -90, lat < 90, long > -180, long < 180) %>%
  arrange(lat, long)   %>%
  dplyr::select(long, lat)
df_sf_temp <- st_as_sf(long_lat_temp, coords = c("long", "lat"))
st_crs(df_sf_temp) <- 4326
all_cells <- df_sf_temp %>% 
  st_make_grid(cellsize = c(0.625, 0.5), 
               offset = c(-179.375 - 0.3125, -89.5 -0.25)) %>% # c(-180 - 0.3125, -90 - 0.25))
  st_as_sf() %>% 
  st_join(df_sf_temp) %>%
  st_transform(st_crs(border_sf))
all_cells$long <- long_lat_temp$long
all_cells$lat <- long_lat_temp$lat
# Initialisation
unique_year <- 1981:2024
chosen_years <- 1:44
```

The `compute_indicator_country` function performs population-weighted aggregation of cell-level indicators to the country level. It is applied year by year, with the complete set of annual estimates obtained through sequential evaluation.

```{r, eval = F, echo = F}
# take time and memory 
# years of population 
list_pop <- list(
  c("1981" = "2000", "1982" = "2000", "1983" = "2000", "1984" = "2000", "1985" = "2000"),
  c("1986" = "2000", "1987" = "2000", "1988" = "2000", "1989" = "2000", "1990" = "2000"),
  c("1991" = "2000", "1992" = "2000", "1993" = "2000", "1994" = "2000", "1995" = "2000"),
  c("1996" = "2000", "1997" = "2000", "1998" = "2000", "1999" = "2000", "2000" = "2000"),
  c("2001" = "2001", "2002" = "2002", "2003" = "2003", "2004" = "2004", "2005" = "2005"),
  c("2006" = "2006", "2007" = "2007", "2008" = "2008", "2009" = "2009", "2010" = "2010"),
  c("2011" = "2011", "2012" = "2012", "2013" = "2013", "2014" = "2014", "2015" = "2015"),
  c("2016" = "2016", "2017" = "2017", "2018" = "2018", "2019" = "2019", "2020" = "2020"),
  c("2021" = "2021", "2022" = "2022", "2023" = "2023", "2024" = "2023"))
# correspondance between colors and population count
m <- rbind(c(255, 255, 190, 255), 
           c(255, 255, 115, 255),
           c(255, 255, 0, 255), 
           c(255, 170, 0, 255), 
           c(255, 102, 0, 255), 
           c(255, 0, 0, 255), 
           c(204, 0, 0, 255), 
           c(115, 0, 0, 255) )

my_min <- c(1, 6, 26, 51, 101, 501, 2501, 5001)
my_max <- c(5, 25, 50, 100, 500, 2500, 5000, 185000)
my_mean <- (my_min + my_max) / 2 # could be improved

# list of countries
unique_m49 <- unique(countries_regions$M49_CODE)

# constant used later to aggregate
my_grid$cste <- 1

compute_indicator_country <- function(k) {
  
  # packages
  library("sf")
  library("terra")  
  years_select <- names(year_pop)[k]
  year_data <- year_pop[k]

  # prepare all variables all years
  # choose all variable merging with the year
  i <- paste0(rep(list_var, each = length(years_select)), "_", 
                rep(years_select, times = length(list_var)))
  
  my_res <- world_sf
  my_res[, i] <- 0
  
  temp <- terra::rast(paste0("landscan/", year_data, "/landscan-global-", year_data, "-colorized.tif"))
  # Be careful : Can take time and memory 
  # Here we transform value c(255, 255, 190, 255) by 1 (lower bound) and 5 (upper bound), etc.
  r_mean <- subst(temp, m, my_mean)
  # aggregate by a factor 4 the data 
  # r_mean <- aggregate(r_mean, fact=4, fun="sum")
  
  # rasterize for variables - all years 
  temp_rast <- rast(my_grid[, c("long", "lat", c(i, "cste"))], type = "xyz")
  crs(temp_rast)  <- "epsg:4326"

  # choose one country 
  for(l in na.omit(unique_m49)) {
    print(l)
    
    # select one country 
    temp_cnty <- my_res[which(my_res$M49_CODE == l), ]
    temp_cnty_buff <- st_buffer(st_transform(temp_cnty, 4326), 0.625)
    
    
    # crop the data into the polygon
    crop_cells <- crop(temp_rast, temp_cnty_buff, snap = "out", mask=F)
    
    # Population in the country
    #temp_cnty
    #newext <- ext(0, 169.5, 0, 80)
    #z <- terra::as.polygons(newext)
    # Intersect with species
    #temp_cnty <- terra::intersect(vect(temp_cnty), z) 

    cm_mean <- crop(r_mean, temp_cnty, mask=F)
  
    # we keep the cells falling into the polygon
    my_sample <- terra::resample(crop_cells, cm_mean)
    # my_sample <- crop(my_sample, temp_cnty, mask=T)

    cm_mean <- crop(cm_mean, temp_cnty, mask=T)
    # plot(my_sample[[1]], col = scales::alpha(map.pal("viridis", 100), 0.4))
    # plot(cm_mean, add = T, legend = F)
    # plot(st_geometry(temp_cnty), add = T )
    # nearest neighbours between 
    if(length(table(cm_mean[, , 1])) == 0) {
      cm_mean[, , 1] <- 1
    }
    nn <- terra::zonal(my_sample, cm_mean, "sum", na.rm=TRUE)
    # temp_pop <- table(cm_mean[, , 1])
    nb_habitant <- sum(nn$lyr1 * nn$cste) # sum(temp_pop * as.numeric(names(temp_pop)), na.rm = T)
    temp_res <- sapply(nn[i], function(x) sum(x * nn$lyr1, na.rm = T) / nb_habitant)

    my_res[which(my_res$M49_CODE == l), i] <- as.list(temp_res)
  }
  # delete temporary files
  save(my_res, file = paste0("country_res/country_", years_select, ".RData"))
  return(my_res)
}

list_pop <- unlist(list_pop)
year_pop <- list_pop

for(k in 1:44) {
  temp <- compute_indicator_country(k)
  tmpFiles(current=TRUE, orphan=FALSE, old=FALSE, remove=TRUE)
}


# summarize the results
load("country_res/country_1981.RData")
final_indicator <- my_res
for(k in 1982:2024) {
  load(paste0("country_res/country_", k, ".RData"))
  final_indicator <- cbind(final_indicator, st_drop_geometry(my_res)[, c(9, 37:(ncol(my_res) - 1))])
} 
save(final_indicator, file = "results/final_indicator.RData")
```

# Summary of constructed climate indicators

We provide a set of functions for visualizing country-level indicators computed annually from 1981 to 2024:

* `my_plot_evol` plots the functional time series of a given indicator n_var for all countries, grouped by macro-geographic region.
* `my_plot_density` generates density plots of the indicator `n_var`, grouped by five-year periods and macro-geographic region.
* `plot_map` displays spatial maps of the indicator n_var, averaged over five-year periods.

```{r, warning = F, message = F}
###################################
####### Function for time series
my_plot_evol <- function(n_var, use_log = F, y_lim = NULL) {
  
    t_var <- title_var[list_var == n_var]
    n_var <- paste0(n_var, "_")
    chosen_years <- 1981:2024
  ### plot of diff temperatures 
  temp_E <- final_indicator %>%
    dplyr::select("NAME", "SREGION", paste0(n_var, chosen_years)) %>%
    pivot_longer(cols = 3:(2 + length(chosen_years)), names_to = "years", values_to = "my_var") %>%
    mutate(years = substr(years, nchar(years)-3, nchar(years))) %>%
    mutate(years = as.Date(paste0(years, "-06-01")))
  temp_E$un <- countrycode::countrycode(temp_E$NAME, "country.name", "un")
  temp_E$Time <- as.numeric(substr(temp_E$years, 1, 4))
  
  # merge with the population 
  temp_E <- merge(temp_E, pop, by = c("un", "Time")) %>%
    filter(!is.na(SREGION), !is.na(un)) 
  temp_E_agg <- temp_E %>%
    st_drop_geometry() %>%
    mutate(my_var = my_var * PopTotal) %>%
    group_by(SREGION, years) %>%
    summarise(my_var = sum(my_var),
              PopTotal = sum(PopTotal)) %>%
    mutate(my_var = my_var / PopTotal)
  
  if(use_log) {
    temp_E$my_var <- log(1 + temp_E$my_var)
    temp_E_agg$my_var <- log(1 + temp_E_agg$my_var)
  }
  
  if(is.null(y_lim)) {
    y_lim <- range(temp_E$my_var)
  }
  temp_E %>%
    filter(!is.na(SREGION), !is.na(un)) %>%
    ggplot() + 
    aes(x = years, y = my_var, group = NAME) +
    ylab(t_var) +
    ylim(y_lim[1], y_lim[2]) +
    geom_line() +
    geom_line(data = temp_E_agg, aes(x = years, y = my_var, group = SREGION), 
              color = "red") +
    scale_x_date(breaks = as.Date(paste0(c(seq(1980, 2025, by = 5)), "-01-01")),
               date_labels = "%Y") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
    facet_wrap(~ SREGION)
}


###################################
####### Function for densitu plot

my_plot_density <- function(n_var, use_log = F) {
  
    chosen_years <- 1981:2024 
    t_var <- title_var[list_var == n_var]
    n_var <- paste0(n_var, "_")
  ### plot of diff temperatures 
  temp_E <- final_indicator %>%
    dplyr::select("NAME", "SREGION", paste0(n_var, chosen_years)) %>%
    pivot_longer(cols = 3:(2 + length(chosen_years)), names_to = "years", values_to = "my_var") %>%
    mutate(years = substr(years, nchar(years)-3, nchar(years))) %>%
    mutate(years = as.Date(paste0(years, "-01-01")))
  temp_E$un <- countrycode::countrycode(temp_E$NAME, "country.name", "un")
  temp_E$Time <- as.numeric(substr(temp_E$years, 1, 4))
  temp_E$Period <- 
    factor(names(list_period)[sapply(temp_E$Time, function(x) which(sapply(list_period, function(y) x %in% y)))],
           levels = names(list_period),
           labels = c("1981-1984", "1985-1989", "1990-1995", "1995-1999",
                      "2000-2004", "2005-2009", "2010-2014", "2015-2019",
                      "2020-2024"))
  
  # merge with the population 
  temp_E <- merge(temp_E, pop, by = c("un", "Time")) %>%
    filter(!is.na(SREGION), !is.na(un)) 

  
  temp_E_agg <- temp_E %>%
    st_drop_geometry() %>%
    mutate(my_var = my_var * PopTotal) %>%
    group_by(SREGION, years) %>%
    summarise(my_var = sum(my_var),
              PopTotal = sum(PopTotal)) %>%
    mutate(my_var = my_var / PopTotal)
  
  if(use_log) {
    temp_E$my_var <- log(1 + temp_E$my_var)
    temp_E_agg$my_var <- log(1 + temp_E_agg$my_var)
  }
  temp_E %>%
    filter(!is.na(SREGION), !is.na(un)) %>%
    ggplot() + 
    aes(x = my_var, color = Period) +
    xlab(t_var) +
    geom_density() +
    scale_color_brewer(palette = "RdBu", direction = -1) +
   #  geom_density(data = temp_E_agg, aes(x = my_var), color = "cyan", linetype = "dashed") +
    facet_wrap(~ SREGION, scales = "free_y") +
    xlim(min(temp_E$my_var), ifelse(n_var %in% c("wsdi_upp_"), 150, max(temp_E$my_var)))
}

#########################
####### function for plotting maps

plot_map <- function(n_var) {
  t_var <- title_var[list_var == n_var]
  u <- n_var
    
  date_title <- c("1980-1985", "1985-1990","1990-1995", "1995-2000", "2000-2005", 
                  "2005-2010", "2010-2015", "2015-2020", "2020-2024")

  temp <- st_drop_geometry(final_indicator)[, paste0(u, "_", names(list_period))]
  vec_temp <- na.omit(as.vector(as.matrix(temp)))    
  if(u %in% c("t2m_diff", "t2min_diff", "t2max_diff", "prec_diff")) {
      pal1 <- rev(RColorBrewer::brewer.pal(8, "RdBu"))
      bk_1 <- round(classInt::classIntervals(vec_temp[vec_temp < 0], 4, "kmeans")$brks, 
              digits = 6)
      bk_2 <- round(classInt::classIntervals(vec_temp[vec_temp >= 0], 4, "kmeans")$brks, 
              digits = 6)
      bk <- c(bk_1[1:4], 0, bk_2[2:5])  
      bk[1] <- min(vec_temp)
      bk[length(bk)] <- max(vec_temp)
    } else {
        bk <- round(classInt::classIntervals(vec_temp, 9, "kmeans")$brks, digits = 6)
        bk[1] <- min(vec_temp)
        bk[length(bk)] <- max(vec_temp)
      if(u %in% c("wet", "prec_5days") | substr(u, nchar(u) - 2, nchar(u)) == "low") {
        pal1 <- RColorBrewer::brewer.pal(9, "Blues")
      } else {
      pal1 <- RColorBrewer::brewer.pal(9, "Reds")
      }
    }


    layout(matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10), ncol = 3, byrow = TRUE), 
         heights = c(0.3, 0.3, 0.3, 0.1))
    
    for(k in 1:length(list_period)) {
      nom_var <- paste0(u, "_", names(list_period)[k])
      my_var <- final_indicator[[nom_var]]
      ind <- findInterval(my_var, bk, all.inside = TRUE)
      
      par(mar = c(0.5, 0, 0, 0.5))
      #plot(st_geometry(world), col = pal1[ind], 
      #   border = "lightgrey", pch = 15, cex = 0.5, lwd = 0.001)
      
      plot(st_geometry(world), col = pal1[ind], 
         border = pal1[ind], pch = 15, cex = 0.5, lwd = 0.001)
      
      plot(st_geometry(world_iso_3_agg), border = "lightgrey",
           lwd = 0.001, add = T)

      #plot(st_geometry(frontiers), lty = 2, add = T,
      # border = "lightgrey", lwd = 0.1)

    title(date_title[k], line = -1.15)
    
    plot(sea, col = scales::alpha("lightblue", 0.3), border = rgb(0.2, 0.2, 0.2), add = T)
    plot(st_geometry(world_union), add = T, border = rgb(0.2, 0.2, 0.2))
    plot(long_sf, add = T, col = "lightgrey")
    plot(lat_sf, add = T, col = "lightgrey")
    }
    ## parameters for legend
    poly_leg_temp <- vector("list", length(bk) - 1)
    for(k in 1:(length(bk) - 1)) {
      poly_leg_temp[[k]] <- rbind(c(-8000000 + (k - 1) * 2000000, 9200000), 
                              c(-8000000 + 1000000 + (k - 1) * 2000000, 9200000),
                              c(-8000000 + 1000000 + (k - 1) * 2000000, 8900000),
                              c(-8000000 + (k - 1) * 2000000, 8900000),
                              c(-8000000 + (k - 1) * 2000000, 9200000))
    }
    poly_leg <- st_sfc(st_polygon(poly_leg_temp[1]))
    for(k in 2:length(poly_leg_temp)) {
      poly_leg <- c(poly_leg, st_sfc(st_polygon(poly_leg_temp[k])))
    }
  # legend
  #plot(0, 0, type = "n", xaxt = "n", yaxt = "n", bty = "n", xlab = "", ylab = "")
  par(mar = c(0, 0, 0, 0))
  plot(poly_leg, col = pal1)
  temp_coord <- st_coordinates(st_centroid(poly_leg))
  bk_round <- round(bk, 3)
  for(k in 1:length(poly_leg)) {
    if(k == 1) {
      my_text <- paste0("<", bk_round[2])
    } else {
      if(k == (length(bk) - 1)) {
        my_text <- paste0(">=", bk_round[length(bk) - 1])
      } else {
        my_text <- paste0("[", bk_round[k], "; ", bk_round[k+1], "[")  
      }
    }
    text(temp_coord[k, 1], temp_coord[k, 2] + 100000, my_text, pos = 3)
  }
  title(t_var, line = -4.1)
}


list_period = list(
  "80_85" = 1981:1984,
  "85_90" = 1985:1989,
  "90_95" = 1990:1994,
  "95_00" = 1995:1999,
  "00_05" = 2000:2004,
  "05_10" = 2005:2009,
  "10_15" = 2010:2014,
  "15_20" = 2015:2019,
  "20_24" = 2020:2024
)

for(i in 1:length(list_period)) {
  for(j in 1:length(list_var)) {
    final_indicator[[paste0(list_var[j], "_", names(list_period)[i])]] <-
      rowMeans(st_drop_geometry(final_indicator)[paste0(list_var[j], "_", list_period[[i]])])
  }
}

wpp2024 <- readxl::read_xlsx("data/WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_FULL.xlsx",
                        sheet = "Estimates", skip = 16) 

pop <- wpp2024 %>%
  dplyr::select(3, 5, 11, 13, 14, 15) %>%
  rename(Location = 1, LocID = 2, Time = 3, PopTotal = 4, PopMale = 5, PopFemale = 6) %>%
  mutate(PopTotal = as.numeric(PopTotal),
         PopMale = as.numeric(PopMale),
         PopFemale = as.numeric(PopFemale))
pop$un <- countrycode::countrycode(pop$Location, "country.name", "un")
```

Several functions are required to implement the functional scan statistic:
* `find_all_cluster` computes the full set of unique candidate clusters used in the scan procedure.
* `compute_h` performs the functional scan test for a given indicator across all candidate clusters.
* `plot_stat_scan` generates the final visualization, combining a map of the detected scan clusters with the functional trajectories that characterize each cluster.

```{r, warning = F, message = F}
####################
#### Scan Statistics functions 

source("codes/HFSS.R")
draw.circle <- function (x, y, radius, nv = 100) {
  ymult <- 1
  angle.inc <- 2 * pi/nv
  angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
  for (circle in 1:length(radius)) {
    xv <- cos(angles) * radius[circle] + x
    yv <- sin(angles) * radius[circle] * ymult + y
  }
  invisible(list(x = xv, y = yv))
}

find_all_cluster <- function (Matcoord) {
  n <- nrow(Matcoord)
  Matdist <- as.matrix(dist(Matcoord, upper = TRUE))
  vecord_list <- vector("list", n)
  for (k in 1:n) {
    vecord_list[[k]] <- order(Matdist[, k])
  }
  res_cluster_g1 <- vector("list", 0)
  res_cluster_g2 <- vector("list", 0)
  
  matrix_g1 <- vector("list", n)

  for(k in 1:n) {
    matrix_g1[[k]] <- rep(0, n)
  }
  
  nb_combi <- 0
  for (k in 1:(n-1)) {
    for (j in 1:n) {
      temp_1 <- vecord_list[[j]][1:k]
      temp_2 <- vecord_list[[j]][(k+1):n]

      my_vec <- my_vec_2 <-numeric(n)
      my_vec[temp_1] <- 1
      my_vec_2[temp_2] <- 1
      # my_length <- k
      cond_1 <-  any(matrix_g1[[k]] %*% my_vec == k)
      cond_2 <-  any(matrix_g1[[n-k]] %*% my_vec_2 == n-k)
        
      if (!(any(cond_1) | any(cond_2))) {
        nb_combi <- nb_combi + 1
        res_cluster_g1[[nb_combi]] <- temp_1
        res_cluster_g2[[nb_combi]] <- temp_2
        matrix_g1[[k]] <- rbind(matrix_g1[[k]], my_vec)
      }
    }
  }
  cat("Number of unique combination: ", nb_combi, "\n")
  return(list(vec_g1 = res_cluster_g1,
              vec_g2 = res_cluster_g2))
}

plot_stat_scan <- function(n_var, preposs = F, use_log = F, p_value = F, B = 5) {
  
  my_years <- 1981:2024
  n_years <- length(my_years)
  t_var <- title_var[list_var == n_var]

  X <- t(as(st_drop_geometry(temp_cont)[, paste0(n_var, "_", my_years)],
                  "matrix"))
  if(use_log) {
     X <- log(1 + X) 
  }
    
  
  if(preposs) {
    CWtime <- seq(0, 1, length.out = n_years) # 1:n_years
    CWrange <- c(0, 1) # c(1, n_years)
    CWbasis <- create.fourier.basis(CWrange, 20)
    harmaccelLfd <- vec2Lfd(c(0, (2 * pi / n_years)^2, 0), 
                            rangeval = CWrange)

    CWfd1 <- smooth.basisPar(CWtime, X, CWbasis, 
                         Lfdobj = harmaccelLfd, lambda = 1e-12)$fd
    
    # Discrétisation
    # X <- eval.fd(CWtime, CWfd1)
    # X[X < 0] <- 0
  }

  
  # MLC
  #,res_h <- compute_h(pairs_geo[[1]], pairs_geo[[2]], X, d = 34, plot_eigen = T)
   res_h <- compute_h(pairs_geo[[1]], pairs_geo[[2]], X, d = 10)
   my_cluster_1 <- res_h$vec
  
   temp_1 <- draw.circle(matCoord[my_cluster_1[1], 1], 
                           matCoord[my_cluster_1[1], 2], 
                  as.numeric(dist_proj[my_cluster_1[1], 
                                       my_cluster_1[length(my_cluster_1)]]))
   
   p_value_h_1 <- 0
   if(p_value) {
     pb <- progress_bar$new(total = B)
     for(b in 1:B) {
       pb$tick()
       perm <- sample(ncol(X))
       MatXsim <- X[, perm]
       temp <- compute_h(pairs_geo[[1]], pairs_geo[[2]], MatXsim, d = 10)
       p_value_h_1 <- p_value_h_1 + (res_h$stat < temp$stat)
     }
    cat("p-value MLC: ", p_value_h_1 / 100)
   }
     
  
  new_indices <- data.frame(old = 1:ncol(X),
                          new = 1:ncol(X)) 
  n_geo <- (ncol(X)- length(res_h$vec))
  new_indices[res_h$vec, "new"] <- paste0("a", res_h$vec)
  new_indices[-res_h$vec, "new"] <- 1:n_geo
  row.names(new_indices) <- new_indices$new
  ###

###
  my_pairs_sp_2 <- find_all_cluster(matCoord[-res_h$vec, ])

  cluster_g1_temp <- lapply(my_pairs_sp_2[[1]], function(x) 
    new_indices[as.character(x), "old"])
  cluster_g2_temp <- lapply(my_pairs_sp_2[[2]], function(x) 
    new_indices[as.character(x), "old"])
  
  ind_size <- sapply(cluster_g1_temp, 
                   function(x) (length(x) > 5) & (length(x) < size_max))
  
  # 2LC
  #temp <- compute_h(cluster_g1_temp[-id_pos], cluster_g2_temp[-id_pos], 
  #                X, d = 34, plot_eigen = T)
  temp <- compute_h( cluster_g1_temp[which(ind_size)], cluster_g2_temp[which(ind_size)], 
                  X, d = 10)
  my_cluster_2 <- temp$vec
  
  temp_2 <- draw.circle(matCoord[my_cluster_2[1], 1], 
                           matCoord[my_cluster_2[1], 2], 
                  as.numeric(dist_proj[my_cluster_2[1], 
                                       my_cluster_2[length(my_cluster_2)]]))
     
  p_value_h_2 <- 0
   if(p_value) {
     pb <- progress_bar$new(total = B)
     for(b in 1:B) {
       pb$tick()
       perm <- sample(ncol(X))
       MatXsim <- X[, perm]
       temp <- compute_h(cluster_g1_temp[which(ind_size)], cluster_g2_temp[which(ind_size)], 
                         MatXsim, d = 10)
       p_value_h_2 <- p_value_h_2 + (res_h$stat < temp$stat)
     }
    cat("\n p-value Secondary: ", p_value_h_2 / 100)
   }
    
  col_geo <- rep(rgb(0.9, 0.9, 0.9, alpha = 0.1), nrow(temp_cont))
  cex_geo <- rep(0.7, nrow(temp_cont))
  col_geo[my_cluster_1] <- alpha(cols[1], 0.8)
  cex_geo[my_cluster_1] <- 1
  
  col_geo[my_cluster_2] <- alpha(cols[2], 0.5)
  cex_geo[my_cluster_2] <- 1 
  
#  plot(st_geometry(temp_geo), col = col_geo, border = "lightgrey", lwd = 0.1)

  plot(st_geometry(world_iso_3_agg), border = "lightgrey", lwd = 0.1)
  plot(st_geometry(frontiers), lty = 2, add = T,
       border = "lightgrey", lwd = 0.1)
  
  plot(st_geometry(temp_geo[my_cluster_1, ]), add = T, 
       col = alpha(cols[1], 0.8), border = alpha(cols[1], 0.8), lwd = 1)
  plot(st_geometry(temp_geo[my_cluster_2, ]), add = T, 
       col = alpha(cols[2], 0.8), border = alpha(cols[2], 0.8), lwd = 1)
        
      
  plot(sea, col = scales::alpha("lightblue", 0.3), 
       border = rgb(0.2, 0.2, 0.2), add = T)
  plot(st_geometry(world_union), add = T, border = rgb(0.2, 0.2, 0.2))
  plot(long_sf, add = T, col = "lightgrey")
  plot(lat_sf, add = T, col = "lightgrey")
  

  plot(st_geometry(st_union(temp_geo[my_cluster_1, ])),
       border = cols[1], lwd = 1.2, add = T)

  plot(st_geometry(st_union(temp_geo[my_cluster_2, ])),
               border = cols[2], lwd = 1.2, add = T)


  ###############
  polygon(temp_2$x, temp_2$y, border= cols[2],
             col = alpha(cols[2], 0.4), lty=1, lwd=1)
  
  ###############
  polygon(temp_1$x, temp_1$y, border= cols[1],
             col = alpha(cols[1], 0.4), lty=1, lwd=1)
  
  legend("bottomleft", legend = c("Most likely cluster", "Secondary cluster"),
         fill = c(cols[1], cols[2]), cex = 0.9, box.lty = 0)
  
  matplot(X, type = "l", lty = 1, col ="grey", xlab = "years",
       ylab = t_var, xaxt = "n")
  axis(1, at = seq(0.5, 40.5, by = 5), 
       labels = seq(1980, 2020, by = 5))
  matplot(X[, my_cluster_1], type = "l", lty = 1, col = cols[1], add = T)
  matplot(X[, my_cluster_2], type = "l", lty = 1, col = cols[2], add = T)
  
  cat("MLC: \n", paste(st_drop_geometry(temp_cont)[my_cluster_1, "NAME"],
      collapse = ", "), "\n \n")
    cat("Secondary cluster: \n", paste(st_drop_geometry(temp_cont)[my_cluster_2, "NAME"],
      collapse = ", "))
}

temp_cont <- final_indicator %>% filter(!is.na(M49_CODE))
temp_geo <- world %>% filter(!is.na(M49_CODE))
matCoord <- st_coordinates(st_centroid(temp_geo))
temp_pairs_geo <- find_all_cluster(matCoord)
n_geo <- nrow(temp_geo)
size_max <- n_geo / 4
ind_size <- sapply(temp_pairs_geo[[1]], 
                   function(x) (length(x) > 5) & (length(x) < size_max))
pairs_geo <- list(
  vec_g1 = temp_pairs_geo[[1]][which(ind_size)],
  vec_g2 = temp_pairs_geo[[2]][which(ind_size)]
)
dist_proj <- as(dist(cbind(matCoord[, 1], matCoord[, 2])), "matrix")
```


## Deviation from historical normal

We present the code used to generate the figure titled *Annual values of $\Delta T^{\text{MEAN}}$ from 1981 to 2024, grouped by macro-regions according to the United Nations M49 geoscheme. Red lines represent population-weighted regional averages.*

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "t2m_diff"
#pdf(file = paste0("figures/", u_var, "_ts.pdf"), width = 12 * 0.8, height = 8* 0.8)
my_plot_evol(u_var)
# dev.off()
```

We present the code used to generate the figure titled *Spatial distribution of $\Delta T^{\text{MEAN}}$ across five-year periods from 1981 to 2024. Values are averaged at the national level over each period and expressed as deviations from the 1981–2010 baseline.*

```{r, fig.width = 10, fig.height = 7, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

We present the code used to generate the figure titled *Kernel density estimates of annual $\Delta T^{\text{MEAN}}$ values grouped by five-year periods and UN macro-regions. Each curve reflects the distribution of country-level anomalies within a given region and time window.*

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), 
#    width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

We present the code used to generate the figure titled *Detection of spatial clusters with elevated warming trajectories using the scan statistic for functional data introduced by \cite{smida2025}. The two clusters shown include countries with significantly stronger trends in $\Delta T^{\text{MEAN}}$ compared to the global distribution.*

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F, p_value = F, B = 100)
#dev.off()
```


### Summary 


We present the code used to generate the figure titled *Results of the functional scan statistic for indicators in the Deviation from Historical Norms family ($\Delta T^{\text{MEAN}}$, $\Delta T^{\text{MAX}}$, $\Delta T^{\text{MIN}}$). Most likely clusters and secondary clusters are highlighted for each variable.*

```{r, warning = F, fig.width = 9.8, fig.height = 7}
title_var <- c(TeX(r'($\Delta T^{MEAN}$ (in degree C))'), 
               TeX(r'($\Delta T^{MIN}$ (in degree C))'), 
               TeX(r'($\Delta T^{MAX}$ (in degree C))'), 
               "Total Number of Days Exceeding 35°C",
               "Difference from average precipitation (in mm)", 
               "Total Count of Dry Days", 
               "Total Count of Wet Days",
               "Maximum consecutive 5-days precipitation (in mm)",
               paste0(rep(c("Quantile-based ", "Extremile-based ", "ES-based "), 
                          each = 12),
                      c("WSDI (in days)",
                        "WSD (in days)",
                        "WSEI (in degree C)",
                        "HWF (in days)",
                        "HWD (in days)",
                        "HWEI (in degree C)", 
                        "CSDI (in days)",
                        "CSD (in days)",
                        "CSEI (in degree C)",
                        "CWF (in days)",
                        "CWD (in days)",
                        "CWEI (in degree C)")
                      )
)
#pdf(paste0("figures/indicators/group1.pdf"), width = 9.8, height = 7)
  par(mfrow = c(3, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan("t2m_diff", preposs = F, p_value = F, B = 100)
plot_stat_scan("t2min_diff", preposs = F, p_value = F, B = 100)
plot_stat_scan("t2max_diff", preposs = F, p_value = F, B = 100)
#dev.off()
```

## Persistence of wet/dry conditions and precipitation extremes

**Maximum Precipitation over 5 Days** (not shown in the article)

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "prec_5days"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var)
#dev.off()
```

```{r, fig.width = 10, fig.height = 7, eval = T}
 #pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
 #dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
# pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
# dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
 #pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
# dev.off()
```


**Maximum consecutive dry days** (not shown in the article)


```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "dry"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var)
#dev.off()
```


```{r, fig.width = 10, fig.height = 7, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
#dev.off()
```


### Summary 

We present the code used to generate the figure titled *Results of the functional scan statistic for indicators in the Persistence of Dry/Wet Conditions family ($Dry$, $Wet$, $\Delta P$, and $P5D$). Most likely clusters and secondary clusters are highlighted for each variable.*

```{r, warning = F, fig.width = 12, fig.height = 12}
#pdf(paste0("figures/indicators/group2.pdf"), width = 12, height = 12)
  par(mfrow = c(4, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.6, 0.3, 0.3), 
      las = 1, mgp = c(2.2, 0.7, 0))
plot_stat_scan("dry", preposs = F, p_value = F, B = 100)
plot_stat_scan("wet", preposs = F, p_value = F, B = 100)
plot_stat_scan("prec_diff", preposs = F, p_value = F, B = 100)
plot_stat_scan("prec_5days", preposs = F, p_value = F, B = 100)
#dev.off()
```

## Frequency of Extreme Temperature Events

**Heatwave frequency : $\text{HWF}^{E}$** (not shown in the article)

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "E_hwf_upp" # "ghwr_35" # "wsdi_upp"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var)
#dev.off()
```

```{r, fig.width = 10, fig.height = 7, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
#dev.off()
```


**Cold Extremes: $\text{CWF}^{E}$** (not shown in the article)


```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "E_wsdi_low" # "ghwr_35" # "wsdi_upp"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var)
#dev.off()
```

```{r, fig.width = 10, fig.height = 7, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
#dev.off()
```

### Summary 

We present the code used to generate the figure titled *Results of the functional scan statistic for indicators in the Frequency of Extreme Events family ($GWHR$, $WSDI^E$, $HWF^E$, $CSDI^E$, and $CWF^E$). Most likely clusters and secondary clusters are highlighted for each variable.*

```{r, warning = F, fig.width = 12, fig.height = 15}
#pdf(paste0("figures/indicators/group3.pdf"), width = 12, height = 15)
  par(mfrow = c(5, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.6, 0.3, 0.3), 
      las = 1, mgp = c(2.2, 0.8, 0))
plot_stat_scan("ghwr_35", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_wsdi_upp", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_hwf_upp", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_wsdi_low", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_hwf_low", preposs = F, p_value = F, B = 100)
#dev.off()
```


## Duration and persistence of extreme events

**Warm spell duration ($WSD^{E}$)** (not shown in the article)

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "E_wsd_upp"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var, y_lim = c(0, 75))
#dev.off()
```

```{r, fig.width = 10, fig.height = 7, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
#dev.off()
```

**Cold wave duration ($CWD^{E}$)** (not shown in the article)


```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "E_hwd_low"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var)
# dev.off()
```

```{r, fig.width = 10, fig.height = 7, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
#dev.off()
```

### Summary 

We present the code used to generate the figure titled *Results of the functional scan statistic for indicators in the Duration of Extreme Events family ($WSD^E$, $HWD^E$, $CSD^E$, and $CWD^E$). Most likely clusters and secondary clusters are highlighted for each variable*

 
```{r, warning = F, fig.width = 12, fig.height = 12}
#pdf(paste0("figures/indicators/group4.pdf"), width = 12, height = 12)
  par(mfrow = c(4, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.6, 0.3, 0.3), 
      las = 1, mgp = c(2.2, 0.8, 0))
plot_stat_scan("E_wsd_upp", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_hwd_upp", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_wsd_low", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_hwd_low", preposs = F, p_value = F, B = 100)
#dev.off()
```


## Intensity or excess above thresholds

**Warm spell excess index ($WSEI^E$)** (not shown in the article)


```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "E_wsei_upp"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 9, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
#dev.off()
```

**Coldwave excess index ($CWEI^E$)** (not shown in the article)


```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
u_var <- "E_hwei_low"
#pdf(file = paste0("figures/indicators/", u_var, "_ts.pdf"), width = 12, height = 8)
my_plot_evol(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 9, eval = T}
#pdf(file = paste0("figures/indicators/", u_var, "_map.pdf"), width = 10, height = 7)
plot_map(u_var)
#dev.off()
```

```{r, fig.width = 12, fig.height = 8, warning = F, message = F}
#pdf(file = paste0("figures/indicators/", u_var, "_density.pdf"), width = 12, height = 8)
my_plot_density(u_var)
#dev.off()
```

```{r, warning = F, fig.width = 14, fig.height = 4.5}
#pdf(paste0("figures/indicators/", u_var, "_scan.pdf"), width = 14, height = 4.5)
  par(mfrow = c(1, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan(u_var, preposs = F)
#dev.off()
```


### Summary 

We present the code used to generate the figure titled *Results of the functional scan statistic for indicators in the Intensity of Exceedances family ($WSEI^E$, $HWEI^E$, $CSEI^E$, and $CWEI^E$). Most likely clusters and secondary clusters are highlighted for each variable.*

```{r, warning = F, fig.width = 12, fig.height = 12}
#pdf(paste0("figures/indicators/group5.pdf"), width = 12, height = 12)
  par(mfrow = c(4, 2), oma = c(0, 0, 0, 0), mar = c(3.5, 3.4, 0.3, 0.3), 
      las = 1, mgp = c(2, 0.8, 0))
plot_stat_scan("E_wsei_upp", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_hwei_upp", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_wsei_low", preposs = F, p_value = F, B = 100)
plot_stat_scan("E_hwei_low", preposs = F, p_value = F, B = 100)
#dev.off()
```

